---
title: "최신머신러닝을 이용한 추천 시스템"
header:
#   overlay_image: /assets/images/
# teaser: /assets/images/flutter.png
show_date: false
layout: single
date: 2023-04-24
classes:
  - landing
  - dark-theme
categories:
  - AI, GNN, Meta-Learning
---


# UROP

### 주제 : 최신머신러닝 시스템을 적용한 추천시스템 연구및 분석
<details>
<summary> 1주차 (주제 선정) </summary>
<div markdown="1">   

1. GNN(Graph Neural Network)
2. 메타러닝(Meta-Learning)
    - 거리 기반
    - 최적화 학습 방식
    - 모델 기반
3. LSTM


</div>
</details>

<details>
<summary> 2주차 (추천시스템 분석) </summary>
<div markdown="1">   


# 2주차(추천 시스템 연구동향 분석)

<details>
<summary> --# 메타러닝  </summary>
<div markdown="1">   

## 메타러닝

### **정의**

- **떠오르는 학습 방법이며 적은 데이터를 효율적으로 학습(퓨샷 러닝)**
- **‘메타’라는 단어는 한 차원 위의 개념적 용어로 대상의 전반적인 특성을 반영**
- **데이터의 패턴을 정해진 프로세스로 학습하는 것이 아닌 데이터의 특성에 맞춰서 모델 네트워크의 구조를 변화시키면서 학습**
- **배우는 방법을 배우는 것 (Learning to learn)**

ex) 하이퍼파라미터 최적화, 자동 신경망 네트워크 설계 등등..

### 퓨샷러닝(Few Shot Learning)

**퓨샷 러닝에서의 데이터셋은 크게 두 가지로 나뉜다.**

1. 서포트 셋(Support Set)
    1. 데이터 셋을 학습에 사용하는 데이터
2. 쿼리 셋 (Query Set)
    1. 데이터 셋을 테스트에 사용하는 데이터

이러한 퓨샷 러닝 태스크를 “N-way K-shot”이라고 하며 여기서 n은 카테고리의 개수를 뜻하고 k는 카테코리당 이미지의 수를 의미한다. 일반적으로 성능은 N에 반비례하며 k에 비례한다.

—# 예를 들어 개, 고양이, 말 3개의 카테리고가 있고 각각 4장씩 이미지가 존재한다면 

→ 3-way 4-shot이다. 

### 특징

일반적으로 딥러닝 모델을 훈련시킬 때 대용량의 데이터가 필요하며 현실적으로 방대한 양의 데이터셋을 구축하기는 쉽지 않다. 퓨샷 러닝은 적은 데이터만 있어도 성능이 우수한 모델링이 가능하다.

### 접근 방법

메타 러닝 및 퓨샷 러닝의 대표적 접근 방법은 거리 학습 기반과 모델 기반 학습 방식과 최적화 학습 방식이 존재한다.

- **거리 학습 기반 : 효율적 거리 측정 학습**
- **모델 기반 학습 : 메모리를 이용한 순환 신경망**
- **최적화 학습 : 모델 파라미터 최적화**

**거리 학습 기반(Metric Based Learning)**

메타 러닝의 방법론 중 하나인 거리 학습 기반은 서포트 셋과 쿼리 셋 간의 **거리(유사도)를 측정**하는 방식으로 대신한다. 대표적인 알고리즘은 샴 네트워크(Siamese Neural Network)가 있다.

모델은 주어진 서포트 데이터를 특징 공간에 나타내서 특징을 뽑아내며 같은 클래스면 거리를 가깝게 다른 클래스면 멀게 하는 방식으로 데이터를 분류한다. 쿼리 데이터를 유클리디안 거리가 가까운 서포트 데이터의 클래스로 예측하는 방식이다.

**모델 기반 학습 방식(Model based learning)**

모델 기반 학습 방식은 적은 수의 학습 단계로도 모델의 파라미터를 효율적으로 학습할 수 있는 방식이다.

**모델에 별도의 메모리를 두어 학습 속도를 조절한다.** 대표적인 알고리즘으로는 MANN가 있다.

과거 데이터를 외부 메모리에 저장함으로 효율적으로 문제를 해결하는 방법을 습득하며 새로운 정보를 빠르게 인코딩하고 몇 개의 샘플만 가지고도 새로운 태스크에 적용할 수 있도록 설계되었다.

**최적화 학습 방식(Optimizer learning)**

Few Shot task를 파라미터 최적화 문제로 생각한다.

일반적으로 딥러닝 모델은 기울기의 역전파를 통해 학습을 진행하지만 기울기 기반 최적화 기법은 큰 스케일의 데이터를 위해 설계가 되었기 때문에 적은 수의 샘플에 대한 최적화 기법을 다룬다. 대표적인 알고리즘으로는 MAML알고리즘이 있다.

</div>
</details>

## 0. 추천 시스템 기법 연구동향 분석

정보 통신의 발달로 최근에는 온라인으로 쇼핑하는 사람들이 증가하였다.

하지만 고객의 입장에서는 판매자와 직접적인 소통이 불가능해 다양해지는 아이템들에 대한 사전지식 부족으로 원하는 물건을 고르는데 어려움이 존재한다. 이를 해결하기 위하여 다양한 방법의 추천시스템이 존재한다. 현재는 **정보필터링** 방법과 **연관성 분석** 등이 있다.

## **가장 간단한 추천 방식**

![IMG_52C0ED242834-1](https://user-images.githubusercontent.com/79856225/228569836-cb73c3cd-8802-461a-9e8e-ae0fcd11f70e.jpeg)


1. 베스트셀러기반
    - 특징 : 판매량이 많은 순서대로 상품을 추천
    - 장점 : 개인정보 없이 신속한 추천 가능
    - 단점 : 개인화된 추천이 불가능
2. 최소질의대상 상품결정
    - 특징 : 직접 설문하여 얻은 정보를 통해 상품을 추천
    - 장점 : 개인화된 추천이 가능
    - 고객의 응답이 불완전할 경우 신뢰성 저하

|  | 베스트셀러기반 | 최소질의대상 상품결정 |
| --- | --- | --- |
| 특징  | 판매량이 많은 순서대로 추천 | 직접 설문하여 얻은 정보를 통해 추천 |
| 장점 | 개인정보 없이 신속한 추천  | 개인화된 추천 가능 |
| 단점 | 개인화된 추천이 불가능 | 고객의 응답이 불완전할 경우 신뢰성 ↓ |

## **정보 필터링**

정보 필터링 기법에는 크게 3가지 존재한다.

1. 콘텐츠 기반
2. 협력 필터링
3. 하이브리드

<details>
<summary> 1. 콘텐츠 기반  </summary>
<div markdown="1">   

**특징**

- 사용자가 아이템에 대해 평가한 점수 혹은 과거 구매내역을 바탕으로 미리 선정된 기준을 통해 분류된 아이템 카테고리와 **유사도**를 계산한 후 추천

**장점** 

- 협력필터링과 다르게 추천 대상과 취향이 비슷한 이웃 사용자를 찾을 필요가 없다.
    - 독립적인 정보만을 필요로 한다.
    - 다른 사용자의 정보가 부족할 경우 사용
- 새로운 아이템에 대한 평가점수가 존재하지 않더라도 First rater문제가 발생하지 않는다.
    - 새로운 아이템이여도 그 아이템 속성에 맞게 카테고리에 할당되어 유사도로 추천하기때문

<aside>
❗ first rater : 새로운 아이템에 대해 누군가가 점수를 주기 전까지 핻아 아이템은 추천 리스트에 포함될 수 없는 문제

</aside>

**단점** 

- 과거 구매이력과 정보가 부족할 경우 성능을 보장할 수 없다.
    - 구매이력과 프로필 정보가 없다면 해당 방법으로 구현하는것은 불가능
- 다른 사용자들의 취향이나 선호도를 반영하지 못해 너무 비슷한 상품들만 추천될 수 있음
    - 이러한 문제를 과도한 특수화라고 함
    - 무작위 요소를 추가하는 유전자 알고리즘이나 돌연변이 방식을 사용하면 보다 우수한 성능 보장

**접근 방식**

**(1)아이템 속성 분석**

**구조적 데이터**

- 아이템의 속성이 명확히 정의 되어 있어 있음
- 속성의 개수가 비교적 적고, 각 속성에 해당하는 값이 모두 존재해야 함

**비구조적 데이터**

- 이미지,소리, 텍스트와 같은 데이터
- 최근 들어 급증하고 잇고, 속성 정의가 어렵다는 단점이 존재
- 텍스트로 이루어진 콘텐츠에 대한 연구가 활발히 이루어지고 있음
    - 키워드 분석과 의미 분석 2가지 방식

**비구조적 데이터(키워드 분석)**

아이템간의 키워드를 비교하여 유사도를 계산하여 사용자가 선호하는 아이템과 키워드 유사도가 높은 아이템을 추천하며 대표적으로는 **TF-IDF**가 있다.

**TF : 아이템 내에서 한 단어가 출현한 빈도를 나타내는 값으로, 아이템에서 많이 출현한 단어일수록 높은 값**

**IDF : 출현 빈도가 높더라도 불용어에 해당할 확률이 크므로 해당하는 키워드가 전체 아이템에서 얼마나 가치 있는 키워드인지**

**아이템 내에서 많이 출현하지만 전체 아이템 집합에서는 드물게 출현하는 단어일수록 높은 TF-IDF 값을 가짐**

- 위 과정으로 가중치가 높은 상위 N개의 단어 키워드로 테이블을 생성
- 아이템간 유사도를 계산하기 위해 코사인 유사도를 사용

**문제점**

- 하나의 단어가 다양한 의미를 가지는 경우
    - 실제로는 유사하지않지만 추천 가능성
- 여러 단어가 하나의 의미를 가지는 경우
    - 내용적으로는 유사하지만 유사도가 낮으므로 추천 누락

위 문제점을 해결하기 위하여 의미론 분석의 중요성이 대두되고 있다.

**의미론 분석에서는 품사 별 동의어 관계를 링크로 연결한 대형 네트워크 형태의 워드넷(Wordnet)이 가장 널리 이용되고 있다.**

- **사용자 프로필 정보를 이용하여 추천**
    
    (+) 과거 구매이력 및 다른 사용자 데이터가 없어도 추천 가능
    
    (+) 평가 데이터가 부족한 경우 널리 쓰임
    
    (-) 정확한 정보를 입력하는 사용자를 확보하기 어려움
    
    (-) 사용자 선호 경향 변화에 대한 대처가 힘듬
    
    (-) 정교한 추천 성능을 보장할 수 없음
    
- **과거 구매이력 정보를 분석하여 추천**
    
    (+) 과거 구매이력을 성능향상 
    
    (+) 사용자 선호 경향 변화에 대한 대처 가능
    
    (-) 과거 데이터가 필요
    
    (-) 너무 비슷한 아이템만을 추천할 가능성 존재
    

**콘텐츠 기반 접근방식은 사용자가 직접 입력한 정보를 이용하여 추천하는 방식과 사용자가 과거에 구매한 이력 정보를 통해 추천하는 방식이 존재한다. 여기서 아이템을 추천하기 위해서 TF-IDF식을 통해 아이템 내에서 등장하는 키워드에 대한 값을 계산하는데 해당 식은 단지 아이템 내 단어 출현 빈도수를 계산하므 로 여러 단어가 하나의 의미를 가지거나, 하나의 단어가 다양한 의미를 가지는 경우 제대로 된 추천 가능성이 낮다. 이를 해결하기 위하여 의미론적 분석이 필요하며 워드넷이 가장 널리 이용되고 있다.**

</div>
</details>

<details>
<summary> 2. 협력 필터링  </summary>
<div markdown="1">   

> “이웃이 다른 이웃을 돕는다면 우리의 커뮤니티는 더 강해집니다.” -제니퍼 팔카
> 

**특징**

- 현재까지 가장 우수한 성능을 나타낸다고 알려진 기법으로 특정 아이템에 대해 선호도가 유사한 고객들은 다른 아이템에 대해서도 비슷한 선호도를 보일 것 이라는 기본 가정을 바탕으로 시용자가 아이템에 대해 평가한 정보를 사용해 선호도를 예측한다.

**장점** 

- 콘테츠 기반의 방식보다 정확도가 우수하다.

**단점** 

- 유사도를 측정할 만한 충분한 데이터가 존재하기 않다면 예측이 불가능하다 (Cold Start)
- 누군가가 점수를 주기 전까지는 추천이 이루어 질 수 없다(first rater)
- 코사인거리나 피어슨 상관게수를 이용할 경우 데이터 희소성 문제가 발생
- **데이터 희소성을 해결하기 위한 다양한 연구**
    - 논문추천 시스템
        - 논문의 키워드를 활용하는 방식을 제안
        - 나이브 베이즈 모델 사용
        - 새로운 고객에 대해서는 추천목록을 제공하는 것이 어려움
    - **협력필터링 기법과 사회연결망 기법의 중심성을 결합**
        - 많은 사람들과 비슷한 선호도를 갖는 고객의 취향은 대중적이고 신뢰성이 높다는 가정
        - 고객들 간 유사도를 기반으로 네트워크를 생성
        - 중심성이 높은 사용자들을 새로운 고객의 이웃으로 설정
        - 기존 나이브 베이즈 모델보다 정확성을 향상 시킴
    - **주요 사용자와 일반 사용자로 분류**
        - 주요 사용자 군집 생성
        - 일반 사용자 군집 생성
        - 주요 사용자 군집에는 있지만 일반 사용자 군집에는 없는 아이템을 **일반 사용자에게 추천**
    - **데이터의 차원을 축소하는 방법**
        - 중요하지 않은 사용자나 아이템을 제거 하는 특이값 분해
        - 원본 데이터보다 노이즈가 적어 우수한 성능을 나타냄
    - **낮은 순위 데이터에 손실함수 개념 적용**

**확장성**

- 계산량이 많을 경우 유사도가 큰 순서대로 N개의 사용자 혹은 아이템만을 선정하여 선호도를 예측
- 일관성이 없는 의견을 가진 사용자는 오히려 방해가 됨
    - 콘텐츠기반 + 협력필터링을 모두 사용하여 가중 평균값을 에측 값으로 활용
    - 두 값의 차이가 큰 사용자의 가중치를 낮게 주어 예측 오차를 줄이는 방법
- 고의로 긍정적인 평가 혹은 부정적인 평가를 하는 경우
    - 기계학습 알고리즘을 통해 미리 학습한 뒤 공격을 탐지하는 기법

**접근 방식**

- **기억 기반 협력필터링**
    - 유사도가 높은 사용자가 선택한 아이템을 추천해주는 방식
        - 모델을 구축하지 않고 추천이 요굴될 때마다 휴리스틱 기법을 통해 결과를 도출
    - **같은 항목에 같은 점수를 준 두 고객이 존재할 경우, 이들의 유사도는 높으며 비슷한 취향을 갖고 있다고 볼 수 있다.**
    - 사용자 기반 : 사용자가 입력한 선호도 정보를 이용하여 추천대상고객의 구매이력과 가장 비슷한 사용자가 구매한 아이템을 추천하는 방식
    - 아이템 기반 : 추천하고자하는 아이템을 구매한 사람들이 공통적으로 구매한 아이템을 구매한 사람들에게  해당 아이템을 추천해주는 방식
    
    **유사도**
    
    - 피어슨 상관게수
        - 1에 가까울수록 양의 상관관계, -1에 가까울수록 음의 상관관계, 0은 상관관계 없음
    - 코사인 유사도
        - 다양한 고객들이 서로 다른 척도를 사용할 경우 파악하는 것이 어렵다.
        - 이를 해결하기 위해 보완 코사인 유사도를 제안
    - 스피어만 순위 상관계수
        - 사용자 a와 b의 점수를 각각 순위로 변환한 뒤, 차이를 통해 유사도를 측정
        - 점수의 분포가 매우 극단적일 경우 유용하다.
        - 사용자가 여러 아이템에 대하여 같은 평가점수를 준 경우에는 유사도 측정이 어려움
    
    **선호도 예측**
    
    - 가중합
        - 추천 대상 고객과 사용자간의 유사도가 높을수록 큰 가중치를 부여
    - 단순가중평균
        - 아이템 기반 협력필터링에서 사용
        - TF-IDF를 활용
        
- **모델 기반 협력필터링**
    - 기억 기반 협력필터링을 기본으로 하되, 기계학습 또는 데이터마이닝 기법을 활용하는 것
    - 베이지안, 선형 회귀분석, 마코프 결정 프로세스 등…
    - **나이브 베이즈 모델**
        - 문서분류에서 가장 우수한 성능을 보이고 있는 알고리즘으로 베이즈 정리에 이론적 근거를 두고 있음
        - 각 카테고리에 할당 될 확률을 계산하는 방법
        - 평가 정보나 이용정보가 부족한 신규 컨텐츠 추천 문제를 해결
        - 콘텐츠기반 접근방식의 과도한 특성화 문제의 해결 가능성 제시
    - **군집화**
        - 대표적으로 K-means, DBSCAN, OPTICS 존재
        - 기존 협력필터링에서 유사도를 측정하는 단계에 앞서, 유사한 그룹을 나누는 과정이 추가
        - 예측 정확도가 높아지는 장점
        - 데이터를 분할함에 따라 데이터 희소성 문제 발생
- **차원 축소**
    - 사용자가 구매한 상품이 너무 적으면 추천이 불가능
    - 사용자가 구매한 상품이 너무 많으면 많은 계산 비용이 발생
    - LSI기법을 적용하여 고차원의 행렬을 저차원의 행렬로 차원을 축소하는 방법 존재
    - 차원수가 너무 작으면 계산 속도는 빠르지만 정확도가 낮음
    - 차원수가 너무 높으면 계산 속도는 느리지만 정확도가 높음
        - 적절한 착원 선택이 중요
        - 1차적으로는 군집화를 진행
        - 엔트로피 가중치와 특이값 분행를 동시에 적용

**협력 필터링 접근방식은 이웃한 사용자 또는 아이템의 유사도로 추천하는 기법이다. 협력 필터링 방식은 콘텐츠 기반 방식보다 더 정확하다는 장점이 존재하지만 Cold start, first rater문제가 있다. 이를 해결 하기 위해 다양한 연구가 진행 중에 있다. 협력 필터링 기법은 크게 2가지 방식이 존재한다. 첫 번째로는 기억 기반 협력 필터링이며 해당 방식은 사용자 또는 아이템 기반 방식이 존재한다. 모델 기반 방식은 기억 기반 방식을 기반으로 기계학습과 같은 모델을 사용하는 방법이다. 기억 기반 협업 필터링은 새로운 사용자나 아이템에 대한 추천에 대해 비교적 불안정하며, 사용자나 아이템이 증가할 때 시간과 메모리 문제가 발생할 수 있는 반면, 모델 기반 협업 필터링은 새로운 사용자나 아이템에 대한 추천이 가능하며, 적은 메모리와 높은 정확도를 보장한다. 하지만, 모델링이 어려워 다른 방법보다 많은 전문 지식이 필요**

</div>
</details>


<details>
<summary> 3. 하이브리드  </summary>
<div markdown="1">   

**특징**

- 각 방식의 장점을 극대화하면서 단점은 보완하고 다양한 정보를 효과적으로 활용할 수 있다.
- 모델의 형태에 따라 크게 네 가지로 분류가 된다.
    1. 독릭된 추천 결과를 조합
    2. 콘텐츠 기반 정보를 협업필터링에 적용
    3. LSI, PLSI와 같은 알고리즘을 이용하여 협업필터링의 정보를 콘텐츠기반 접근방식에 융합
    4. 협업필터링과 콘텐츠기반 접근방식을 동시에 고려하는 단일 모델을 구축
        1. MCMC 와 같은 추정모델 또는 베이지안 학습법이 이용

**종류**

1. **다른 추천 기준을 지닌 여러개의 알고리즘을 학습한 뒤 가중평균합을 구하는 방법**
    - 여러 추천 알고리즘들의 결과를 전반적으로 이용 가능
    - 각 추천 점수를 정규화하여야 하며, 가중치를 잘 정의해야 함
2. **여러 개의 추천 엔진중 현재 상황에 가장 적절한 추천 엔진 선택**
    - 현재의 상황을 인지하기 위한 추가적인 계산이 필요’
3. **추천 결과를 혼합하여 보여주는 방법**
    - 다양성을 높게 보여줄 수 있음
4. **모든 변수를 하나의 알고리즘의 변수로 병합**
5. **한 알고리즘이 추천한 아이템을 다른 알고리즘의 후보로 이용**
6. **각각의 알고리즘 추천 점수를 바탕으로 메타 알고리즘을 학습하는 앙상블 방법**

$MCNee et al.(2006)$

- 콘텐츠기반과 협업힐터링에 사용할 수 있는 알고리즘을 제시
- **이웃기반 협업필터링**
    - 세렌디피티(의도치 않게, 우연성)가 높은 경향이 있음
- **나이브 베이지안 판별기**
    - 선택한 논문이 많이 참조된 논문을 먼저 추천
- **PLSI**
    - 사용자-아이템 행렬을 차원축소 방법 중 하나인 PLSI를 통해 학습
    - 선택한 논문과 분야적으로 매우 유사한 논문들이 우선적으로 추천
- **TF-IDF**
    - TF-IDF를 이용하여 콘텐츠 기반 추천
    - 선택한 논문들과 내용이 매우 유사한 논문들이 우선적으로 추천.

$Vozalis and Margaritis(2004)$

- 인구통게학 정보를 이용하여 유사한 이웃들의 정보만을 이용하는 연쇄방법을 제안

$Chow et al.(2014)$

- 사용자의 선호정보를 결합하여 개인화 추천 알고리즘을 고안

$Basilico and Hofmann(2004)$

- 사용자-아이템 행렬과 사용자-아이템의 특성 변수들을 모두 종합하여 유사도 커널을 정의

$Ganu et al.(2009)$

- 리뷰 데이터로 추출된 토픽과 의미 벡터를 이용
- 사용자나 아이템의 해당 리뷰 유무에 따라 추천 알고리즘을 선택할 수 있는 방법을 제안하고 성능을 입증

$Mcauley and Leskovec(2013)$

- 리뷰 데이터로부터 토픽을 추출 시 리뷰 데이터와 점수를 모두 이용하여 토픽을 추출하는 HFT를 제안

$Vozalis and Margaritis(2004)$

- 아이템들에는 숨겨진 변수가 있다고 가정
- 숨겨진 변수를 리뷰 데이터로부터 추출
- 사용자가 선택한 아이템과 유사한 속성을 지닌 다른 아이템을 추천

</div>
</details>


<!-- 
<details>
<summary>  </summary>
<div markdown="1">   

</div>
</details> -->


</div>
</details>




<details>
<summary> 3주차(GNN기반 추천 시스템 조사)  </summary>
<div markdown="1">   

# 3주차(GNN기반 추천 시스템 조사)

## GNN(Grpah Neural Network)

Graph neural networks in recommender systems: a survey

<details>
<summary> 0. 개요  </summary>
<div markdown="1">   

유튜브, 넷플릭스 ,스포티파이와 같은 플랫폼에서 사용자의 방대한 항목(제품, 영화, 뉴스…)에서 관심 있는 항목을 탐색하기 위해 추천 시스템을 사용한다. 사용자의 과거 상호 작용(클릭, 시청, 읽기, 구매…)을 통해 사용자의 선호도를 정확하게 모델링하는 것이 효과적인 추천 시스템의 핵심이다. 

대체로 지난 수십 년 동안 추천 시스템의 주류 모델링 패러다임은 **이웃 방법 → 표현 학습 기반으로 발전해왔다.**


<details>
<summary> —# 이웃방법  </summary>
<div markdown="1">   

**이웃방법**

- **아이템 기반 이웃방법**
    
    아이템기반 이웃방법은 **사용자가 상호작용한 과거 아이템**과 유사한 아이템을 사용자에게 직접 추천한다. 초기 아이템 기반 이웃 접근 방식은 단순성, 효율성, 효과성으로 인해 실제 애플리케이션에서 큰 성공을 거두었다.

</div>
</details>

<details>
<summary> —# 표현학습  </summary>
<div markdown="1">  

**표현 학습**

- **사용자 - 아이템**
    
    사용자와 아이템을 공유 공간에서 연속 벡터로 인코딩하여 직접 비교하는 표현 학습 기반 방식으로 **사용자와 아이템 간의 관계**를 명시적으로 모델링하는 방법론이다. 이 접근 방식은 비선형적이고 단순하지 않은 사용자-아이템 관계를 효과적으로 포착하고 풍부한 데이터 소스를 쉽게 통합할 수 있다는 점에서 인기를 얻고 있다.

</div>
</details>

넷플릭스 프라이즈 경진대회에서 행렬 인수분해 모델이 기존의 이웃 방식보다 추천에 더 우수하다는 사실이 입증된 이후 표현 기반 모델에 대한 관심이 급증했고 그 후 인수분해부터 딥러닝 모델에 이르기까지 사용자와 아이템의 표현을 학습하기 위한 다양한 방법이 제안되었다.

오늘날 딥러닝 모델은 비선형적이고 사소하지 않은 **사용자-아이템 관계를** 효과적으로 포착하고 문맥, 텍스트, 시각 정보 등 풍부한 데이터 소스를 쉽게 통합할 수 있는 능력으로 학술 연구 및 산업 응용 분야에서 추천 시스템을 위한 주요 방법론으로 자리 잡았다. 

이러한 딥러닝 알고리즘 중에서도 추천 시스템의 정보를 **그래프 관점에서 고려하는 그래프 학습 기반 방식이 있다.** 추천 시스템에 있는 대부분의 데이터는 기본적으로 그래프 구조를 가지고 있다. 

—# 추천 시스템에서 그래프 구조의 예로는 이분 그래프가 있으며 이 유형의 그래프는 사용자와 아이템의 두 집합으로 구성되며, 사용자와 아이템 간의 상호 작용(클릭, 보기, 읽기, 구매…)를 나타내는 링크가 있다.




<details>
<summary> —#이분 그래프  </summary>
<div markdown="1"> 

- 그래프의 정점의 집합을 둘로 나눴을 때, **각 집합에 속한 정점끼리는 서로 인접하지 않도록 분할**할 수 있는 그래프를 이분 그래프라고 한다.
- 밑에 그림의 예제에서 사용자를 노란색 정점, 아이템을 파란색 정점이라고 생각하면 된다.
- **사용자 정점은 서로 연결될 수 없으며, 아이템 정점 또한 마찬가지이다.**

<img width="472" alt="스크린샷 2023-03-15 오후 6 48 36" src="https://user-images.githubusercontent.com/79856225/228572352-a77d1b39-8442-4203-890e-b4c395df6ee2.png">


</div>
</details>


이 논문에서는 추천 시스템에서 데이터는 종종 그래프 구조를 가지며, 사용자 및 아이템 노드는 관찰된 상호 작용을 나타내는 링크로 연결되어 있다고 설명한다. 그래프 학습 알고리즘은 사회적 관계 및 지식 그래프와 같은 외부 정보를 포함하여 이러한 데이터를 모델링할 수 있는 방법을 제공한다. 과거에는 인수분해 기반, 분산 표현 기반, 신경 임베딩 기반 등의 그래프 임베딩 기법이 이러한 목적으로 사용되었지만, 최근에는 그래프 신경망(GNN)이 그래프 구조의 데이터에서 학습하는 데 탁월한 능력을 보여 많은 추천 모델에 사용되고 있다.

기존 추천 시스템은 사용자-아이템간의 상호작용만을 추천 신호로 사용하지만, GNN은 상호작용 그래프의 토폴로지 구조를 사용하여 사용자 및 아이템 표현을 개선할 수 있다. 이는 암시적으로만 했던 기존 방식과달리 GNN은 명시적으로 인코딩 할 수 있기 때문이다.

<details>
<summary> —# 토폴로지 구조  </summary>
<div markdown="1">   

그래프에서 서로 다른 요소간의 관계를 의미한다. 추천 시스템의 맥락에서 이는 사용자가 아이템과 상호 작용하는 방식 또는 아이템이 서로 연관되는 방식을 나타낼 수 있다. GNN은 이러한 토폴로지 구조를 사용자와 아이템 간의 상호 작용에만 의존하는 기존 방식보다 더 나은 추천을 위한 추가 신호로 사용할 수 있다.

</div>
</details>

**GNN(그래프 신경망)은 추천 시스템을 위한 유용한 도구로, 추천을 개선할 수 있는 아이템간의 복잡한 관계를 탐색할 수 있기 때문이다.**

학계 연구에 따르면 GNN은 최근 몇 년간 추천 시스템에서 놀라운 성공을 거둔 기법이다. 많은 연구에 따르면 GNN 기반 접근 방식은 공개적으로 사용 가능한 샘플 데이터세트에서 이전 방법보다 성능이 뛰어나고 새로운 최첨단 결과를 달성하는 것으로 나타났다. 또한 GNN은 세션 기반, POI, 그룹, 멀티미디어, 번들 추천 등 다양한 추천 작업에 적용될 수 있는 다양한 변형이 있다. 

GNN은 웹 스케일 추천 시스템과 같은 사용 애플리케이션에 사용되어 고품질 추천 결과를 생성하는데 도움이 되었다. 예를 들어 Pinterest는 수십억 개의 노드와 에지로 구성된 그래프에 **PinSage라는 GNN기반 모델**을 구현하여 사용자 참여도를 향상시켰다.


<details>
<summary> —# PinSage  </summary>
<div markdown="1"> 

PinSage는 30억 개의 노드와 180억 개의 엣지로 구성된 그래프를 기반으로 핀터레스트(Pinterest)에서 개발 및 배포한 GCN(그래프 컨볼루션 네트워크)알고리즘 모델이다. 랜덤워크 기반 기술을 사용하여 고품질의 추천 결과를 생성하며, 온라인 A/B테스트에서 사용자 참여도를 향상시키는 것으로 나타났다.

</div>
</details>


이 논문은 추천 시스템 분야에서 이 특정 조사가 기존 조사와 어떻게 다른지 논의하고 있다. 추천 시스템에 대한 다양한 관점에 초점을 맞춘 설문조사는 이미 존재하지만, **현재 GNN이 어떻게 추천시스템에 사용되고 있는지에 대한 종합적인 검토는 거의 없다**. 본 조사는 **GNN기반 추천 시스템의 발전 상황을 종합적으로 검토**하고, 사용 정보 유형과 추천 작업에 따라 기존 작품을 분류하며, 이 분야의 미해결 과제와 향후 방향에 대해 논의하는 것을 목표로 한다.

이 논문은 GNN기술을 사용하는 추천 시스템에 대한 최신 문헌을 검토하는 것을 목표로 한다. 또한 이 논문에서는 GNN기반 추천 모델을 정리하기 위해 새로운 분류 체계를 제안하고 있으며 이 분류 체계는 다음과 같이 다섯 가지 그룹으로 정의할 수 있다.

1. 사용자-항목 협업 필터링
2. 순차적 추천
3. 소셜 추천
4. 지식 그래프 기반 추천
5. 기타 작업(ex : POI 및 멀티미디어 추천)

</div>
</details>


<details>
<summary> 1. 배경 및 분류(추천시스템과 GNN)  </summary>
<div markdown="1">   

### **1.1 추천 시스템**

추천 시스템은 사용자의 과거 행동이나 관심사를 기반으로 사용자에게 아이템을 추천하는 도구이다. 이 시스템은 학습된 사용자 및 아이템 표현과 점수 함수를 사용하여 항목에 대한 사용자의 선호도를 추정하며 결과 선호도 점수는 확률로 표시 될 수 있다. 

추천 시스템의 일반적인 작업 중 하나는 사용자-아이템 협업 필터링으로, 시스템이 상호 작용을 기반으로 사용자와 아이템의 표현을 학습하는 것이다. 또 다른 방법은 시간 경과에 따른 상호 작용의 순차적 패턴을 분석하여 사용자 표현을 개선하는 것이다.

추천 시스템 분야는 사용자 익명성과 세션 세분화에 따라 다음과 같이 2가지로 나뉠 수 있다.

1. **순차적 추천**
    - 클릭, 시청, 읽기, 구매 등 아이템에 대한 사용자의 **과거 상호 작용을 고려**하는 시스템
2. **세션 기반 추천**
    - 순차적 추천에서 한 단계 더 나아가 **익명의 사용자도 고려**하고 **사용자의 행동을 세션으로 세분화**하여 이를 통해 개별 사용자의 행동 패턴에 따라 **더욱 개인화된 추천**을 제공

—# 세션

**세션은 일정한 기간 내에 웹사이트에서 발생한 사용자 상호작용의 집합이다. 예를 들어 사용자가 웹사이트에 접속하고, 여러 페이지를 방문하고 장바구니에 상품을 담고 결제하고 나가는 과정을 하나의 세션이라 볼 수 있다.**

GNN이 추천에 기여하는 바에 대한 연구 목적상 그 차이는 중요하지 않기 때문에 모든 추천 시스템을 “순차적 추천”으로 지칭하고 있다. 또한 사회적 관계를 사용하여 사용자 표현을 개선하는 “소셜 추천”이라는 또 다른 유형이 있다


<details>
<summary> —# 소셜 추천   </summary>
<div markdown="1">  

소셜 추천은 사회적 관계를 맺고 있는 사람들이 비슷한 관심사와 선호도를 가지고 있으며, 서로의 선택에 영향을 미칠 수 있다는 것을 의미한다. 연구자들은 사용자의 선호도에 초점을 맞추는 것뿐만 아니라 지식 그래프에서 아이템 간의 속성과 의미 관계를 사용하여 아이템의 표현을 개선함으로써 이러한 추천 접근 방식을 개선하려고 노력한다.

</div>
</details> 

### **1.2 GNN**

최근에는 물리 시스템, 단백질 구조, 지식 그래프 등 그래프로 표현되는 데이터와 관련된 작업에서 뛰어난 성능을 보이는 GNN이라는 알고리즘을 사용하는 새롭고 혁신적인 시스템들이 등장햇다. 이 파트에서는 그래프가 무엇인지 설명하고 이미 존재하는 GNN 기술에 대한 개요를 분석한다. 

그래프는 점(노드)과 이를 연결하는 선(엣지)의 집합이다. 노드의 이웃은 노드에 연결된 노드의 집합이다. 그래프는 방향이 있는 방향 그래프거나 방향이 없는 무방향 그래프가 존재하며, 또한 동질(모든 노드와 엣지가 동일)이거나 이질(노드 또는 엣지가 다름)일 수도 있다. 하이퍼그래프는 하나의 엣지가 두 개이상의 노드를 연결할 수 있는 그래프 유형이다. 

GNN은 반복적인 프로세스를 사용하여 인접 노드의 특징 정보를 집계하고 이를 현재 중앙 노드 표현과 통합한다. 이는 집계 및 업데이트 작업을 모두 포함하는 여러 레이어를 쌓아 수행된다. 그 결과 제공된 그래프 데이터를 기반으로 보다 정확한 예측이 가능하다.

집계 단계에서는 평균 풀링 또는 어텐션 메커니즘을 사용하여 인접 노드의 특징을 결합한다. 업데이트 단계에서는 GRU라는 연결 또는 합계 연산과 같은 다양한 전략을 사용하여 집계된 피처를 중앙 노드 피처와 통합한다. 

**추천 시스템에 사용되는 그래프 신경망(GNN)기법은 5가지가 존재한다.**


<details>
<summary> 1. GNC(Graph Convolutional Network)  </summary>
<div markdown="1">   

- GCN은 Graph Convolutional Network의 약자로, 그래프 구조의 데이터에 **합성곱 연산을 적용하는 GNN의 한 종류**이다. 합성곱 연산은 이미지나 텍스트와 같은 격자 구조의 데이터에 잘 작동하는데, 이를 그래프 구조의 데이터에도 확장할 수 있다.
- GCN은 각 노드가 자신과 인접한 노드들의 정보를 공유하고 학습하는 방식으로 작동한다. 이렇게 하면 노드 간의 상관관계를 잘 반영할 수 있다.

</div>
</details>

<details>
<summary> 2. GraphSAGE(Graph SAmple and aggreGatE)  </summary>
<div markdown="1">   

- GraphSAGE는 각 노드가 **자신과 인접한 노드들의 특성을 샘플링하고 집계하는 함수를 학습**하는 방식으로 작동
- GraphSAGE는 각 노드에 대해 고정된 수의 이웃을 선택한 다음 평균, 합계 또는 최대 풀링 기법을 사용하여 해당 이웃의 정보를 집계한다.
- 이 집계된 정보를 현재 노드의 특징과 연결하고 비선형 활성화 함수와 학습 가능한 변환 행렬을 통과시켜 해당 노드의 업데이트된 특징을 얻는다.
- GraphSAGE의 장점은 새로운 노드나 그래프에도 임베딩을 생성할 수 있다는 것이다. **기존**의 **GNN은 각 노드마다 고유한 임베딩을 학습**하므로 새로운 데이터에 적용하기 어렵지만 **GraphSAGE**는 **인접한 노드들의 특성을 활용**하여 임베딩을 생성하므로, **이전에 보지 못한 데이터에도 유연하게 대응할 수 있다.**

</div>
</details>

<details>
<summary> 3. GAT(Graph Attention Network)  </summary>
<div markdown="1">   

- Graph Attention Network의 약자로, **그래프 구조의 데이터에 어텐션 메커니즘을 적용하는 GNN의 한 종류**이다. 어텐션 메커니즘은 입력 데이터의 **중요한 부분에 집중**하는 방식으로 작동하는데, 이를 그래프 구조의 데이터에도 확장가능하다.
- GAT은 각 노드가 자신과 인접한 노드들의 정보를 어텐션 가중치로 조합하여 학습하는 방식으로 작동한다. 이렇게 하면 노드 간의 상관관계와 특성을 잘 반영할 수 있습니다. GAT은 인접 행렬을 사용하지 않고 각 이웃 노드마다 다른 어텐션을 부여하여 자신의 임베딩을 업데이트한다.
- 일반적으로 LeakyReLU함수를 사용한다.
- GAT을 사용하는 이유는 사용자와 아이템 간의 관계를 그래프로 표현하고, 어떤 아이템에 더 집중할지 결정할 수 있기 때문

</div>
</details>

<details>
<summary> 4. GGNN(Graph Gated Neural Network)  </summary>
<div markdown="1"> 

- **그래프 구조의 데이터에 GRU를 적용하는 신경망의 한 종류이다.**
- GGNN은 그래프의 노드와 엣지에 있는 특성을 활용하여 노드 임베딩을 생성하고, 이를 바탕으로 다양한 그래프 분석 문제를 해결할 수 있다.
- GGNN은 message passing이라는 방식으로 학습합니다. message passing이란 각 노드가 자신과 인접한 노드들과 정보를 주고받는 과정으로 GGNN은 message passing을 통해 각 노드의 임베딩을 업데이트하고, GRU를 사용하여 임베딩의 변화를 제어한다.

—# GRU

GRU는 Gated Recurrent Unit의 약자로, 순환 신경망(RNN)의 한 종류이다. GRU는 RNN이 장기 의존성 문제를 해결하기 위해 LSTM을 변형한 모델로, LSTM보다 간단한 구조를 가지고 있고 LSTM과 비슷한 성능을 보여주면서도 매개변수가 적기 때문에 효율적인 학습이 가능하다.

</div>
</details>

<details>
<summary> 5. HGNN(Hypergraph Neural Network)  </summary>
<div markdown="1">   

- **하이퍼그래프 구조를 사용하는 신경망의 한 종류**
- 하이퍼그래프란 간단한 그래프와 달리 **엣지가 두 개 이상의 노드를 연결할 수 있는 구조**로, 고차원이고 복잡한 데이터 상관관계를 표현할 수 있다.
- HGNN은 다중 모달 데이터나 이질적인 데이터와 같은 복잡한 실제 문제에 적용될 수 있으며  기존의 그래프 신경망보다 더 효과적인 표현 학습을 가능하게 한다.

![Untitled](https://user-images.githubusercontent.com/79856225/228573556-3173c8c3-89ad-491d-96dc-e288bce7d996.png)


</div>
</details>

### 1.3  GNN을 사용하는 이유

최근 연구자들은 추천 시스템에 그래프 신경망을 사용하는 많은 연구를 제안하고 있다. **GNN을 사용하는 가장 큰 이유**는 GNN 기술은 데이터를 그래프 구조로 표현하고 분석하는 데 유용하기 때문이다. **많은 추천 시스템이** 사용자-아이템 간의 상호작용을 위한 이분 그래프나 아이템 주문을 위한 **시퀀스 그래프와 같은 그래프 구조를 사용**한다. 사회적 관계나 지식 그래프와 같은 다른 데이터 유형도 자연스럽게 그래프 구조를 갖는다.

다양한 유형의 데이터에 대해 효과적인 추천모델을 만드는 일은 쉽지 않다. 그러나 GNN을 사용하면 더 나은 추천 결과를 위한 패턴을 효과적으로 학습할 수 있다. 예를 들어 GNN은 사용자-아이템 표현을 학습하고 비순차적 추천 작업에 대한 사용자 선호도를 예측할 수 있다.

또한 GNN은 소셜 네트워크와 같은 추가 정보를 사용자-아이템 이분법 관계에 통합 그래프로 통합하여 보다 정확한 추천을 제공한다.

GNN은 사용자와 아이템 간의 상호 작요인 협업 신호를 보고 이러한 신호를 사용하여 사용자와 아이템을 더 잘표현한다.

<img width="721" alt="스크린샷 2023-03-15 오후 10 51 58" src="https://user-images.githubusercontent.com/79856225/228573754-e8ad3067-67ae-4cc4-b29e-08d84a670000.png">


이 단원에서는 추천 시스템이 그래프 구조를 사용하여 추천을 개선하는 방법에 대해 설명한다. 특히, 아이템과 아이템 간의 상호작용 그래프를 구성하고 랜덤워크 알고리즘을 사용하여 항목의 순위를 매기는 ItemRank의 사용에 대해 중점적으로 설명한다 GNN은 그래프가 아닌 모델보다 추천에 더 효과적이다.

### 1.4 GNN을 기반으로 한 추천시스템의 종류

GNN은 그래프 신경망을 사용하여 과거 상호 작용에서 사용자 선호도를 모델링하는 추천 시스템의 한 유형이다. 이번 파트에서는 **그래프 임베딩 프레임워크에 따라 분류**하고 각 **유형과 관련된 장점과 한계를 분석**한다. 

그래프가 구조화되는 방식은 표현되는 정보의 유형에 따라 달라진다. 예를 들어 소셜 네트워크는 동종 그래프로 표현할 수 있고, 사용자-아이템 상호 작용은 이분 그래프 또는 두 개의 동종 그래프(사용자-사용자 및 아이템-아이템)로 표현할 수 있다. 효율적인 그래프 신경망 구조를 설계하는 것은 집계 및 업데이트 작업, 네트워크 깊이와 같이 사용되는 정보의 유형에 따라 달라진다. 소셜 추천은 소셜 네트워크 정보를 사용하고 지식 그래프 기반 추천은 지식 그래프 내 아이템 간의 의미 관계를 활용하는 등 추천 작업은 사용되는 정보의 유형과 밀접하게 연관되어 있다.

</div>
</details>

<details>
<summary> 2. USER-ITEM 협업 필터링 </summary>
<div markdown="1">   

사용자-아이템 협업 필터링은 사용자가 상호작용하는 아이템을 사용하여 아이템의 표현을 개선하는 것이다. GNN 기법은 정보 확산을 모델링하고 사용자-아이템간의 상호 작용에서 고차 연결성을 포착하는 효율성을 개선하는 데 사용되었다. 다음 이미지는 사용자-아이템간의 상호작용 정보에 GNN을 적용하는 과정이다.

<img width="706" alt="스크린샷 2023-03-15 오후 11 23 17" src="https://user-images.githubusercontent.com/79856225/228574203-c4c38944-019c-492e-8717-f3006d14c6b8.png">

협업 신호를 캡처하는 데 GNN기법을 충분히 활용하기 위해 고려해야 할 네 가지 주요 이슈가 있다.

**1. Graph Construction(그래프 구성)**

- GNN을 사용하여 분석할 데이터를 위한 구조를 만드는 것
- 원본 그래프에는 사용자와 아이템 노드 및 이들의 상호 작용이 있다.
- GNN을 적용할 때는 원래의 이분 그래프를 사용할지, 2홀 이웃을 기반으로 동질 그래프를 만들지 결정해야 한다.
- 시간을 절약하기 위해서는 전체 그래프 대신 대표적인 이웃을 샘플링 해야함

**2. Neighbor Aggregation(이웃 집계)**

- 네트워크에서 인접한 노드의 정보를 결합하는 프로세스를 말한다.
- 이웃 노드의 중요성을 고려할지, 중앙 노드와의 상호 작용을 모델링할지 등 이웃 노드를 어떻게 처리할지 결정하는 작업이 포함되어 있다.

**3. Information Update(정보 업데이트)**

- 중앙 노드의 표현을 이웃 노드의 표현과 결합하는 방법

**4. Final Node Representation(최종 노드 표현)**

- 사용자가 어떤 아이템을 좋아할지 예측하려면 사용자의 전반적인 선호도를 이해해야 함
- 사용자와 사용자가 상호 작용한 아이템에 대한 모든 정보를 결합
- 마지막 레이어의 노드 표현을 사용할지 아니면 모든 레이어의 노드 표현을 결합하여 최종 표현을 만들지 선택

### 2.1 **Graph Construction(그래프 구성)**

많은 연구에서 사용자와 아이템의 이분법 그래프에 GNN을 사용했다고 설명한다. 그러나 원본 그래프에 직접 GNN을 사용하는 것은 비효율적일 수 있다. 그 이유는 원본 그래프가 사용자-아이템 표현을 학습하기에 충분히 포괄적이지 않기 때문이다. 효율성은 대규모 그래프에 대한 이웃 정보를 계산할 때 문제가 되며, 이는 높은 계산 비용을 초래한다.

사용자-아이템간의 상호작용 데이터에 대한 **GNN의 효과와 효율성을 개선하기 위해** 연구자들은 원래의 이분법 **그래프 구조를 강화**하는 전략을 모색해 왔다. 그래프 신경망을 사용하여 **사용자-아이템 협업 필터링을 개선**하는 **두가지 전략**이 있다.

 **(1) 그래프 구조를 풍부하게 하기 위해 엣지를 추가** 

**(2) 가상 노드를 도입하여 사용자-아이템 상호작용을 보다 명확하게 포착**

Multi-GCCF, DGCF, DHCF, HiGNN 등 여러 방법에서 이러한 전략을 채택하여 사용자-아이템 표현을 더 잘 학습하고 계산 비용을 절감했다. 

대규모 그래프 기반 추천 작업을 위해 GNN을 효율적이고 확장 가능하게 만들기 위해 샘플링 전략이 제안되었다. **PinSage**는 ****무작위 도보 기반 샘플링(Random-walk-based sampling) 기법을 사용하여 중앙 노드에 직접 인접하지 않더라도 방문 횟수가 가장 높은 인접 노드를 선택하는 방법이다. **Multi-GCCF 및 NIA-GCN**과 같은 방법은 무작위 샘플링 전략을 사용하여 고정된 수의 인접 노드를 선택한다. 이 전략은 원본 그래프 정보 유지와 계산 효율성 사이의 균형을 유지한다. 그래프 기반 추천 모델의 품질과 효율성은 이웃을 구성하는 데 사용되는 샘플링 전략에 따라 달라지며, 보다 효율적인 샘플링 전략을 연구하고 개발해야 할 필요성이 있다.

![Untitled](https://user-images.githubusercontent.com/79856225/228574222-852c9b39-5b33-4fff-8842-06b821d0b17d.png)

### 2.2 **Neighbor Aggregation(이웃 집계)**

그래프 이론 분야에서 정보가 네트워크를 통해 확신되는 방식은 인접 노드의 정보가 결합되는 방식에 따라 달라진다. 집계 단계가 이를 결정하며, **평균 풀링**은 인접 노드의 정보를 균등하게 결합하는 데 사용되는 **일반적인 방법**이다. 그러나 이 방법은 더 중요한 그래프에는 적합하지 않을 수 있다. 이 문제를 해결하기 위해 일부 방법에서는 **그래프에서의 위치에 따라 노드에 가중치를 할당**하는 **“차수 정규화”** 를 사용한다.

—# **평균 풀링**

평균 풀링은 인접 노드의 평균을 취하여 노드에 대한 표현을 형성하는 것이다. 

**PinSage(그래프 기반 추천 시스템)**는 랜덤 워크라는 샘플림 전략을 사용하여 이웃의 벡터 표현을 집계한다. 이 방법은 정규화된 방문 횟수를 기반으로 이웃에게 중요성을 할당하지만 연결된 노드 간의 관계는 고려하지 않는다. 

상식적으로 사용자의 관심사와 일치하는 아이템이 더 자주 추천되어야 한다. **MCCF**와 **DisenHAN**은 관심도 메커니즘을 사용해 사용자의 관심사를 기반으로 어떤 아이템이 더 중요한지 학습한다. **NGCF**는 사용자가 관심 있는 항목의 기능이나 사용자가 추천 항목에서 원하는 기능을 강화하기 위해 요소별 상품을 사용한다. **NIA-GCN**은 그래프 기반 추천 작업에서 이웃 내 관계 정보를 보존하는 문제를 해결하는 방법이다. 사용자-사용자 또는 아이템-아이템 관계와 같은 이웃 간의 상호 작용을 명시적으로 포착하기 위해 모든 두 이웃간의 요소별 곱셈을 사용하는 쌍별 이웃 집계 접근 방식을 사용한다.

### 2.3 **Information Update(정보 업데이트)**

노드의 이웃 노드로부터 정보를 수집한 후에는 추가 정보 전파를 위해 **노드의 표현을 업데이트하는 것이 중요**하다. 노드의 표현을 업데이트하는 기존 방법은 노드의 원래 정보를 유지하는지 아니면 이웃 노드의 집계된 표현을 위해 완전히 폐기하는지에 따라 **2가지 범주로 분류할 수 있다.**

1. 사용자-아이템 노드의 **원본 정보를 완전히 버리고** 이웃 노드의 집계된 표현을 **새로운 중앙 노드 표현으로 사용**
2. **노드**자체와 그 **이웃 메시지**를 모두 고려(**두가지 표현을 결합**)
    
    두 가지 표현을 결합하는 다양한 방법이 존재한다. 가장 간단한 방법은 두 표현을 더하거나 평균을 내는 것이다. 또 다른 접근 방식은 두 표현을 연결하고 비선형 변환을 적용하여 더 복잡한 특징 상호 작용을 허용하는 것이다. 그러나 일부 연구에 따르면 비선형 변환이 성능을 크게 향상시키지 못하기 때문에 일부 모델은 비선형성을 제거하여 프로세스를 단순화한다.
    

### 2.4 **Final Node Representation(최종 노드 표현)**

GNN에서는 레이어별 프로세스를 통해 각 깊이에 대한 노드 표현을 생성한다. 예측을 하려면 사용자와 아이템의 전체적인 표현이 필요하다. 일반적으로 마지막 레이어의 노드 벡터를 최종 표현으로 하지만 서로 다른 레이어에서 얻은 표현은 연결을 통해 전달되는 서로 다른 메시지를 강조한다. 하위 레이어 표현을 개별 특징을 반영하고 상위 레이어 표현은 이웃 특징을 반영한다. 최근 연구에서는 서로 다른 계층의 메시지를 통합하여 출력으로 표현된 모든 연결으 이점을 활용한다.

### 2.5 요약

**1. Graph Construction(그래프 구성)**

그래프 구성이란 사용자와 아이템 간의 관계를 표현하기 위해 **그래프 구조를 만드는 과정**을 말하며 사용자-아이템 이분 그래프는 이러한 관계를 표현하는 간단한 방법입니다. 그러나 일부 **노드의 연결 수가 적은 경우** 에지 또는 노드를 추가하면 **그래프 구조를 개선할 수 있다.** 노드 주변을 샘플링하는 것도 계산 효율성을 위해 수행할 수 있지만 효과와 효율성 간의 절충이 필요로한다. 효과적인 샘플링 전략에 대해서는 더 많은 연구가 필요하다.

**2. Neighbor Aggregation(이웃 집계)**

이웃 집계는 그래프 또는 네트워크에서 인접한 노드의 정보를 결합하는 프로세스를 말한다. 인접 노드가 서로 다른 경우, 세심한 가중치를 사용하여 정보를 결합하는 것이 동일한 가중치를 사용하거나 차수별로 정규화하는 것보다 낫지만 인접 노드가 비슷한 경우에는 동일한 가중치를 사용하거나 차수별로 정규화하는 것이 더 쉬울 수 있다. 프로세스를 개선하기 위해 이웃 노드가 서로 영향을 미치는 방식이나 중앙 노드가 이웃 노드에 연결되는 방식을 명시적으로 모델링하는 것이 유용할 수 있지만, 더 많은 데이터 세트에서 테스트해야 한다.

**3. Information Update(정보 업데이트)**

원래 노드를 제거하는 대신 원래 형태와 주변 노드의 정보를 사용하여 노드를 업데이트하는 것이 더 좋다. 최근의 일부 연구에 따르면 일반적인 그래프 신경망 모델의 단순화된 버전이 실제로 원래 모델보다 더 나은 성능을 발휘할 수 있다는 사실이 밝혀졌다.

**4. Final Node Representation(최종 노드 표현)**

마지막 레이어의 표현만 사용하는 대신 모든 레이어를 함께 사용하는 것이 좋다. 가중 풀링과 연결이라는 두 가지 일반적인 기술이 있다.

<img width="773" alt="스크린샷 2023-03-20 오후 7 09 38" src="https://user-images.githubusercontent.com/79856225/228574242-fcdb813c-b1d9-4424-bfd8-87699ac5de6e.png">

</div>
</details>

<details>
<summary> 3. 순차적 추천 </summary>
<div markdown="1">   

순차적  추천은 사용자의 이전 행동을 기반으로 다음에 사용자가 관심을 가질 만한 것을 예측하는 방법이다. 여기에는 사용자가 상호 작용한 아이템의 순서에서 패턴을 캡처하고 해당 순서를 기반으로 추천을 생성하는 것이 포함됩니다. 아이템의 시퀀스를 일종의 그래프로 취급할 수 있으며, 이러한 개념으로 인해 사용자의 순차적 행동에서 전환 패턴을 포착하는 데 그래프 신경망(GNN)이 점점 더 많이 사용되고 있다. GNN은 시퀀스를 그래프로 모델링하고 아이템 전환의 패턴을 분석하는 데 도움이 될 수 있다. **순차 추천에서 GNN을 사용할 때 그래프 구성, 정보 전파, 순차 선호도라는 세 개의 주요 이슈를 해결**해야 한다. 다음 그림은 순차 추천에서 GNN의 전체 프레임워크이다.

<img width="834" alt="스크린샷 2023-03-20 오후 6 57 46" src="https://user-images.githubusercontent.com/79856225/228574870-6ebdccdc-1540-44d3-96eb-ea3b7a96812f.png">

**1. Graph Construction(그래프 구성)**

- 데이터를 시퀀스 그래프로 변환해야 함
- 각 시퀀스에 대한 하위 그래프를 독립적으로 구성
- 연속된 두 아이템 사이가 아닌 연속된 여러 아이템 사이에 엣지를 추가
- 위 2개의 항목 중 더 나은것을 선택해야 함

**2. Information Propagation(정보 전파)**

- 전환 패턴을 포착하기 위해 최적의 정보 전파 방법을 결정하는 것이 중요
- 연결된 아이템에 대해 순차 순서를 구분해야 하는지 여부는 불분명

**3. Sequential Preference(순차 추천)**

- 사용자의 가장 최근 활동을 기반으로 사용자의 다음 선호도를 예측
- 사용자의 순차적 행동에서 전환 패턴을 포착하기 위해 사용자의 시간적 선호도를  아이템 표현을 시퀀스로 통합
- 연속적인 시간 패턴을 향상시키는 두 가지 방법은 주의 풀링 또는 RNN 구조를 활용

### 3.1 **Graph Construction(그래프 구성)**

사용자-아이템 상호작용은 이분 그래프 구조를 가지는 반면 **순차적 동작은 시간 순서대로 시퀀스로 표현**된다. 순차 추천에 GNN을 사용하기 위해서는 사용자의 순차적 행동을 기반으로 한 순서 그래프를 구성해야 한다. 

다음 그림은 순차적 행동으로부터 그래프를 생성하는 다양한 방법을 보여준다. 이 과정은 순차적 추천에 GNN을 적용하는 데 필요하다. 가장 간단한 방법은 각 시퀀스의 각 항목을 노드로 처리하고 연속적으로 클릭한 두 아이템 사이에 엣지를 추가하여 각 시퀀스에 대한 방향 그래프를 구성하는 것이다. 하지만 사용자 시퀀스의 길이가 짧은 경우가 많이 때문에 이 접근 방식은 대부분의 시나리오에서 효과적이지 않을 수 있다.

최근 연구에서는 동일한 사용자 또는 전체 데이터 세트의 **추가 행동 시퀀스를 사용**하여 원래 시퀀스 그래프 구조를 보강하는 전략을 제안했고 이러한 전략은 단일 시퀀스 내에 더 많은 노드와 연결을 추가하는 전략과 여러 시퀀스를 함께 결합하는 전략으로 나눌 수 있다.

<img width="740" alt="스크린샷 2023-03-20 오후 7 01 59" src="https://user-images.githubusercontent.com/79856225/228574881-eb581919-e74b-4e6f-b28d-250a2bd01696.png">

1. 사용자 행동 데이터의 추가 시퀀스를 사용하여 아이템과 아이템간의 관계에 대한 이해도를 높임
    - 과거 사용자 시퀀스나 다른 유형의 행동 시퀀스와 같은 다양한 소스에서 가져올 수 있음(HetGNN)
    
    —# HetGNN : 모든 행동 시퀀스를 분석하고 동일한 시퀀스에 있는 아이템 사이에 행동 유형을 엣지 유형으로 엣지를 생성
    
2. 전체 시퀀스의 전반적인 특성을 반영하기 위해 연속된 아이템 사이에 엣지를 추가하거나 가상 ‘스타’ 노드를 도입하는 등 현재 시퀀스의 그래프 구조를 조정

### 3.2 **Information Propagation(정보 전파)**

GNN프레임워크는 일반적으로 이전 아이템과 다음 아이템의 정보를 평균화하여 결합하고 GRU 구성 요소를 사용하여 인접 노드와 중앙 노드의 정보를 통합하여 방향 그래프에 정보를 전당하는 데 사용된다. 이를 통해 시퀀스 크래프에서 아이템 간의 전환 패턴을 효율적으로 전파하고 캡쳐할 수 있다. 일부 방법은 어텐션 메거니즘을 사용하여 특정 이웃에 더 많은 중요성을 부여한다.

### 3.3 **Sequential Preference(순차 추천)**

GNN은 아이템 간의 장거리 종속성을 포착하는 데 한계가 있다. 따라서 사용자의 시퀀스 선호도를 반영하기 위해 시퀀스의 마지막 아이템의 표현을 제한한다. 따라서 연구자들은 효과적인 시퀀스 표현을 얻기 위해 시퀀스 내 아이템 표현을 통합하는 전략을 제안했다.

시퀀스에서는 아이템마다 중요도나 우선순위가 다르기 때문에 아이템 표현을 효과적으로 통합하기 위해 어텐션 메커니즘이 일반적으로 사용된다.

NISER와 GCE-GNN과 같은 일부 접근 방식은 위치 임베딩을 추가하여 위치를 인식하는 아이템 표현을 얻고, FGNN은 반복적인 사용자 선호도 업데이트를 위해 GRU와 어텐션 메커니즘을 사용한다. 한편, DHCN과 COTREC은 세션 간 그래프를 통합하여 두 단계에서 학습한 순차적 표현을 결합함으로써 시퀀스 그래프를 강화한다.

### 3.4 요약

**1. Graph Construction(그래프 구성)**

그래프를 구성하는 방법은 다양하며 **어떤 방법이 더 나은지에 대한 합의는 아직 없으며** 세션 간 그래프를 통합하면 추천 시스템의 성능을 개선하는 데 도움이 될 수 있다.

1. 단순히 연속된 항목 사이에 엣지를 추가
2. 행동 시퀀스의 그래프 구조를 조정

**2. Information Propagation(정보 전파)**

그래프 네트워크 전체에 **정보를 전파하는 방법은 다양**하며 **방법마다 계산 비용과 성능 향상 측면에서 서로 다른 장단점이 존재**하며 이 또한 **합의된 최적의 방법은 아직 없다.** 일부 더 복잡한 방법은 계산이 증가하는 대신 더 나은 성능을 얻을 수 있다. 최종적으로는 어떤 방법을 사용할지 결정하는 것은 애플리케이션의 특정 요구 사항과 제약 조건에 따라 달라질 수 있다.

**3. Sequential Preference(순차 추천)**

**특정 순서에 따라 항목을 추천할 때는 일반적으로는 어텐션 메커니즘을 사용**하여 해당 아이템의 표현을 결합한다. 연구자들은 성능을 더욱 개선하기 위해 위치 임베딤을 추가하여 아이템의 순서를 파악하는 실험을 진행하였고 **RNN 구조를 사용하면 모든 순차적 추천 작업에서 성능을 향상시킬 수 있는지는 아직 모른다.**

해당 그림은 세 가지 주요 문제를 해결하기 위해 검토된 모델에서 사용된 주요 전략에 대한 개요이다.

<img width="983" alt="스크린샷 2023-03-21 오후 7 20 58" src="https://user-images.githubusercontent.com/79856225/228574898-9df92bb4-9b7a-40ad-8139-43651f6f6840.png">

</div>
</details>

<details>
<summary> 4. 소셜 추천  </summary>
<div markdown="1">   

**소셜 추천 시스템**은 사용자의 소셜 네트워크에서 얻은 정보를 사용하여 추천을 개선한다. 이는 **소셜 네트워크에 연결된 사람들은 비슷한 선호도를 가질 것**이라는 생각에 기반한 것이다. ex)같은 전공은 가진 그룹들은 같은 관심사를 가질 확률이 높음

소셜 추천 시스템에서는 사용자 간의 소셜관계를 정규화 도구로 사용하여 사용자 표현을 제한하는 방법도 있고, 이러한 관계를 입력을 통합하여 원래 사용자 임베딩을 개선하는 방법도 있다. 그래프 학습 관점에서 보면, **이전 연구**들은 각 **사용자의 1차 이웃을 모델링**하는 것으로 볼 수 있다. 하지만 **실제로 사용자는 친구의 친구에게도 영향을 받을 수 있다**. 이전 연구들에서 고차 영향 확산을 무시하면 최적이 아닌 추천 성능으로 이어질 수 있다. GNN은 사용자가 다른 사람들과의 관계에 의해 어떻게 영향을 받는지 시물레이션할 수 있기 때문에 추천 시스템에서 소셜 정보를 모델링하는 데 널리 사용된다. **GNN은 재귀적인 소셜 확산 과정을 포착할 수 있어 사용자 행동과 선호도를 정확하게 표현할 수 있다.**

GNN을 사용하여 소셜 정보를 모델링할 때는 다음과 같은 두 가지 주요 문제를 해결해야 한다

**1. Influence of Friends (친구의 영향력)**

- 모든 친구가 동일한 수준의 영햑력을 가지고 있는가
- 일부 친구가 다른 친구보다 더 많은 영향력을 가지고 있는가
- 정확한 추천을 하려면 다양한 수준의 영향력을 가진 친구를 구분하는 것이 중요

**2. Preference Integration(선호도 통합)**

- 친구와의 사회적 관계와 아이템과의 상호작용을 통합해야 함

### 4.1 **Influence of Friends (친구의 영향력)**

소셜 네트워크에서는 **사용자 간의 연결이 얼마나 강한지 불분명**한 경우가 많다. 이러한 연결을 사용하여 추천을 할 때는 각 친구가 얼마나 영향력이 있는지 파악해야 추천이 더 정확해질 수 있다. 기존 모델에서는 모든 친구의 영향력이 동일하다고 가정했지만, **사용자는 사회적 유대 관계가 강하거나 선호도가 비슷한 친구의 영향을 받을 가능성이 더 높기 때문**에 이는 정확하지 않다. **DiffNet은 평균 풀링 연산**을 사용하여 이 문제를 해결하려고 시도했지만, **이러한 동등한 영향력 가정은 실제로는 신뢰할 수 없다**. 현재는 이를 고려하기 위해 **어텐션 메커니즘을 사용하여 서로 다른 이웃의 영향력을 차별화**하여 전반적인 성능을 개선하는 것이 일반적인 접근 방식이다. Song 연구원 등은 사용자의 행동을 모델링하기 위해 순환 신경망을 사용하고, **현재 관심사를 기반으**로 소셜 연결의 영향력을 파악하기 위해 그래프 어텐션 신경망을 사용하는 **DGRec이라는 방법을 제안**했다. **어텐션 메커니즘은** 추천 시스템에서 친구의 영향력을 결정할 때 **평균 풀링 연산에 비해 더 나은 접근 방식**이며 친구마다 영향력 수준이 다르다는 가정을 확인하여 서로 다른 친구의 영향력을 구분할 수 있다. 신뢰할 수 없는 소셜 관계를 포함하면 성능에 부정적인 영향을 미칠 수 있으므로 추천에 통합할 소셜 관계를 신중하게 선택하는 것은 중요하다. **ESRP는 자동 인코딩 메커니즘을 사용하여 관련 없는 관계를 필터링하고 새로운 이웃을 탐색함**으로써 이 문제를 해결한다. **DiffNetLG는 암묵적 로컬 영향력을 사용하여 관찰되지 않은 사회적 관계를 예측**한다.

### 4.2 **Preference Integration(선호도 통합)**

소셜 추천에는 사용자-아이템 상호작용과 소셜 그래프라는 2가지 유형의 관계가 포함된다. 소셜 정보를 사용하여 사용자 선호도를 더 잘 이해하기 위해 **이 2가지 네트워크를 결합하는 2가지 전략**이 있다.

1. 밑에 그림 (a)와 같이 **각 네트워크에서 별도의 사용자 특징을 학습**한 다음 이를 최정 선호도 벡터에 통합하는 방법
2. 밑에 그림(b)와 같이 사용자-아이템 상호작용과 소셜 네트워크를 **단일 네트워크로 결합**하고 GNN을 사용하여 네트워크 전체에 정보를 확산시키는 방법

<img width="915" alt="스크린샷 2023-03-21 오후 7 51 40" src="https://user-images.githubusercontent.com/79856225/228575491-ae9c89a3-fd39-43bc-a2d7-81d441b5017c.png">

1번 방식으로 개별적으로 처리할 경우 **사용자-아이템 이분 그래프에 대한 고급 방법을 직접 적용할 수 있다는 장점**이 있으며, **영향력 프로세스를 시뮬레이션 하는 데 GNN기법이 적합하다는 장점**이 있다. 두 관계에서 학습한 사용자 표현의 통합은 두 네크워크 사용자 표현을 합치는 **선형성** 또는 다층 퍼셉트론을 사용하여 두 표현 간의 기능 상호 작용을 강화하는 **비선형성 조합** 메커니즘을 사용할 수 있으며 널리 채택되고 있다. 

DiffNet은 두 공간의 사용자 표현을 동등하게 취급하고 합 풀링 연산을 통해 결합하는 반면, DANSER은 동일한 가중치 조합을 제공하는 대신 사용자-아이템 쌍을 이루는 특징에 따라 가중치를 동적으로 할당한다.

2번 방식은 **두 네크워크를 하나로 통합**하고 GNN기법을 적용하여 영향력 프로세스를 시뮬레이션하는 것이다. 1번 방식의 장점은 두 네트워크의 확산 깊이를 차별화할 수 있다는 점이며, 2번째 전략의 장점은 **고차적인 사회적 영향력과 관심사 확산을 모두 통합**적으로 모델링할 수 있다는 점이다. 선형성 및 비선형성 조합을 포함하여 두 관계에서 학습한 사용자 특징을 통합하는 데 다양한 방법이 사용된다.

DiffNet++는 2단계 관심 네트워크를 통해 그래프에서 사용자 노드를 업데이트하는 모델이다. 그래프에서 서로 다른 두 가지 유형의 이웃, 즉 상호작용한 아이템과 소셜 네트워크의 친구로부터 얻은 정보를 결합한다. 이는 각 유형의 이웃에 대해 개별적으로 GAT 메커니즘을 사용하여 수행된다.

SEFrame은 그래프 네트워크를 사용하여 사회적 관계, 사용자-아이템 상호작용, 아이템 전환에서 얻은 정보를 결합하는 방식이다. 2단계 어텐션 네트워크를 활용하여 정보를 전파한다. 어떤 전략이 가장 효과적인지는 아직 근거가 없기 때문에 불확실하다.

### 4.3 요약

소셜 추천에는 두 가지 이슈가 존재한다.

1. I**nfluence of Friends (친구의 영향력)**
    
    모든 친구를 동등하게 대하기보다는 서로 다른 친구의 영향력을 고려하는 것이 좋다. 한 가지 접근 방식은 소셜네트워크의 노이즈를 기반으로 소셜 관계를 자동으로 조정하는 것이다.
    
2. **Preference Integration(선호도 통합)**
    
    선호도 통합은 추천 시스템에서 사용자 선호도를 형성하기 위해 2가지 정보 소스, 즉 사용자-아이템 상호작용과 소셜 관계를 결합하는 것을 말한다. 이러한 그래프를 결합하는 방법은 두 그래프를 개별적으로 고려할지 하나의 그래프로 통합할지에 따라 달라진다. 별도의 그래프를 사용하는 경우, 사용자 선호도는 이 두 그래프에서 학습된 전체 특징을 통합한 것인 반면 통합 그래프의 경우 일반적으로 채택되는 전략은 집계 스키마이다.
    

<img width="965" alt="스크린샷 2023-03-21 오후 8 23 31" src="https://user-images.githubusercontent.com/79856225/228575503-aad02319-fbba-482d-8397-fdf57745d97b.png">

</div>
</details>


<details>
<summary> 5. 지식 기반  </summary>
<div markdown="1">  


소셜 네트워크는 사용자 관계에 대한 이해를 높이는 데 사용되며, **지식 그래프는 속성을 통해 아이템 특징을 향상시키는 데 사용**된다. 이를 통해 **아이템 간의 연관성을 탐색**하고 사용자 상호 작용을 기반으로 추천 아이템의 해석 가능성을 개선하는 등의 이점을 얻을 수 있다. 하지만 지식 그래프는 여러 엔티티 유형과 관계로 구성된 **복잡한 구조로 인해 사용하기 어려울 수 있다.** 일반적으로 사용되는 방법은 지식 그래프 임베딩(KGE)를 사용하여 지식 그래프를 전처리하여 개체와 관계의 임베딩을 학습하지만, 이러한 방법은 전환 제약 조건으로 의미적 연관성을 모델링하는 데 중점을 두기 때문에 링크 예측과 같은 그래프 관련 작업에 더 적합하다. 메타 경로 기반 방법은 예측 모델에 입력되는 메타 경로를 수동으로 정의하며 도메인 지식이 필요하고 복잡한 지식 그래프에 대해 시간이 많이 든다.

지식 그래프 기반 추천의 개념에는 사용자-아이템 상호작용 데이터와 지식 그래프를 모두 사용하여 아이템 간의 관계를 파악함으로써 아이템에 대한 사용자의 선호도를 결정하는 것이 포함된다. 이 접근 방식은 사용자-아이템 상호작용 신호를 지식 그래프와 통합하는 방법과 지식 그래프에서 엔티티 간의 다양한 유형의 관계를 고려한 집계 함수를 설계하는 방법이라는 2가지 주요 과제를 해결 해야한다.

**—# 엔티티**

지식 기반 추천시스템에서 엔티티란 텍스트에서 의미있는 정보를 추출하기 위해 이름이 있는 사람, 장소, 조직 등과 같은 명사적인 개체를 의미하며 이러한 엔티티들은 자연어 처리 기술을 이용해 추출된다.

**1. Graph Construction(그래프 구성)**

- 그래프에 사용자 노드를 포함
- 사용자 노드를 사용하여 관계의 중요도를 구분

**2. Relation-aware aggregation(관계 인식 집계)**

- 지식 그래프에는 엔티티 간에 다양한 유형의 관계가 존재
- 관계 인식 집계는 이러한 연결된 엔티티의 정보를 효과적으로 결합

### 5.1 **Graph Construction(그래프 구성)**

그래프를 만들 때 중요한 고려 사항 중 하나는 사**용자 상호 작용의 신호를 그래프에서 사용할 수 있는 지식과 결합**하는 방법이다. 이를 그래프 구축에서 **협업 신호와 지식 정보를 통합하는 작업**이라고 한다.

지식 그래프 기반 추천을 개선하기 위해 사용자 노드를 엔티티 유형으로 통합하고 사용자아와 아이템 간의 관계를 “상호작용”으로 표현하여 사용자-아이템 상호작용을 지식 그래프와 결합하는 것이 한 가지 접근 방식이다. 이는 KGAT, MKGAT, CKAN과 같은 모델에서 수행된다. 연구자들은 지식 그래프에서 사용자-아이템쌍과 사용자가 과거에 상호작용한 아이템 및 관련 의미를 연결하는 하위 그래프를 구축하는 데 주력했다. 이는 지식 그래프의 풍부한 정보를 활용하여 아이템 간의 연관성을 명시적으로 파악하고 아이템에 대한 사용자의 선호도를 추정함으로써 지식 그래프 기반 추천 시스템을 개선하기 위한 것이다.

AKGE는 TransR을 사용하여 엔티티의 임베딩을 사전 학습하고, 연결된 엔티티 간의 쌍별 유클리드 거리를 계산한 후, 경로가 짧을 수록 더 안정적인 연결을 반영한다는 가정하에 대상 사용자와 아이템 노드 간의 거리가 가장 짧은 K개의 경로를 선택하여 지식 그래프에서 하위 그래프를 구성한다.

ATBRG라는 방법은 여러 계층의 엔티티 이웃을 철저히 검색하여 겹치는 엔티티를 사용하여 사용자 행동과 대상 아이템을 연결하는 경로를 복원함으로써 이 문제를 해결한다. 이 접근 방식은 사용자-아이템 쌍과 더 관련성이 높은 하위 그래프를 얻는 데 도움이 된다. ATBRG 방법은 중요한 정보에 집중하기 위해 링크가 하나만 있는 엔티티를 잘라내어 그래프의 크기를 조절하는데 도움이 된다. 이 접근 방식은 효과적이지만 엔티티 임베딩을 사전 학습하거나 경로를 철저하게 검색하고 정리하는 데 많은 시간이 소요될 수 있어서 효율적인 하위 그래프 구성 전략을 찾으려면 추가 조사가 필요하다.

일부 연구자들은 지식 그래프에서 관계에 대한 사용자 선호도를 고려하기 위해 다른 접근 방식을 사용한다.  KGCN과 KGNN-LS는 사용자 노드를 사용하여 엔티티 간의 다양한 관계에 가충치를 할당한다.

### 5.2 **Relation-aware aggregation(관계 인식 집계)**

그래프 신경망은 연결된 개체와 개체 간의 관계를 모두 고려하여 지식 그래프에서 정보를 더 잘 포착할 수 있다. 추천 시스템에서는 사용자의 역할도 중요하다. 그래프 주의 네트워크(GAT)를 사용하면 연결된 노드를 기반으로 적응형 가중치를 부여할 수 있으며, 대부분의 작업은 점수 함수를 사용하여 연결된 엔티티의 가중 평균을 기반으로 중앙 노드를 업데이트한다. 일부 연구에서는 사용자 노드를 지식 그래프에서 또 다른 유형의 엔티티로 취급하며, 사용자 선호도가 업데이트 과정에서 다른 엔티티에 전달된다. 이러한 작업은 관계에 대한 사용자의 관심사를 명시적으로 모델링하지 않고, 연결된 노드와 관계에 따라 엔티티의 영향력을 차별화하며 KGAT모델은 관계 공간에서 연결된 엔티티 간의 거리를 기반으로 가중치를 할당한다. 

### 5.3 요약

지식 그래프 기반 추천에는 두 가 지이슈가 존재한다.
**1. Graph Construction(그래프 구성)**

- 사용자 노드를 엔티티 유형으로 간주
- 사용자 노드를 관계를 구분하기 위해 암시적으로 사용

**2. Relation-aware aggregation(관계 인식 집계)**

- 연결된 엔티티의 정보를 집계하기 위해 GAT의 변형을 사용
- 사용자 노드가 없는 그래프의 경우 사용자 표현을 사용하여 관계에 가중치 할당
- 관련성이 높은 엔티티와 관계에 초점을 맞출 수 있다는 장점이 있지만 계산 시간이 더 많이 걸리고 추가 조사가 필요하다.

</div>
</details>

<details>
<summary> 6. 결론  </summary>
<div markdown="1">  

GNN을 추천시스템에 사용하는 것은 인기를 끌고 있다. 그 이유는 그래프 데이터에 대한 학습에서 GNN이 우수한 결과를 보여줬기 때문이다. 최근의 GNN 기반 추천 시스템 관련 연구들을 정리하기 위한 분류 체계를 제안하고, 각 분류별 대표 모델들이 채택하고 있는 주요 이슈와 전략, 그리고 장점과 한계가 있다. 이 논문에서는 GNN에 대한 전반적인 이해를 제공하는 것을 목표로 한다.

</div>
</details>

</div>
</details>



<details>
<summary> 4주차(GNN을 이용하여 추천 시스템 구현 LightGCN)  </summary>
<div markdown="1">   

# 4주차(GNN을 이용하여 추천 시스템 구현 LightGCN)


<details>
<summary> GNN(Graph Neural Networks)  </summary>
<div markdown="1">   

### 1. Graph

그래프는 점(노드)과 이를 연결하는 선(엣지)의 집합이다. 노드의 이웃은 노드에 연결된 노드의 집합이다. 그래프는 방향이 있는 방향 그래프거나 방향이 없는 무방향 그래프가 존재하며, 또한 동질(모든 노드와 엣지가 동일)이거나 이질(노드 또는 엣지가 다름)일 수도 있다. 하이퍼그래프는 하나의 엣지가 두 개이상의 노드를 연결할 수 있는 그래프 유형이다. 

![1](https://user-images.githubusercontent.com/79856225/230766654-8ae81048-d2b8-42d8-a4b8-d7a3ea735628.png)

![Untitled 크게](https://user-images.githubusercontent.com/79856225/230766752-bda724d6-3934-41ec-9c3c-59f3607ce917.jpeg)


**Grpah = G(V,E)**

### 2. GNN

GNN은 Graph Neural Network의 약자로, 그래프 데이터 분석에서 사용하는 딥러닝 모델이다. 예를 들어, 소셜 네트워크는 친구 관계를 그래프로 표현할 수 있다.

GNN은 이러한 그래프 데이터를 입력으로 받아서, 각 노드의 임베딩을 추출하거나, 그래프 전체를 분류하는 등의 작업을 수행한다. GNN은 일반적으로 **메시지 전달 방식을 사용**하여, 각 노드의 **임베딩을 계산**합니다. 이때, **각 노드의 이웃 노드와의 관계를 이용**하여, 해당 노드의 임베딩을 갱신한다.

GNN은 반복적인 프로세스를 사용하여 **인접 노드의 특징 정보를 집계**하고 이를 현재 중앙 노드 표현과 통합한다. 이는 **집계 및 업데이트 작업을 모두 포함하는 여러 레이어**를 쌓아 수행된다. 그 결과 제공된 그래프 데이터를 기반으로 보다 정확한 예측이 가능하다.

**집계 단계**에서는 **평균 풀링** 또는 **어텐션 메커니**즘을 사용하여 인접 노드의 특징을 결합한다. 업데이트 단계에서는 **GRU**라는 연결 또는 합계 연산과 같은 다양한 전략을 사용하여 집계된 피처를 중앙 노드 특징과 통합한다. 

**그래프에서 중앙노드란,** 그래프 구조에서 중심에 위치한 노드를 의미한다. 예를 들어, 소셜 네트워크에서 친구 관계를 그래프로 표현했을 때, 친구들 사이에서 가장 많은 연결을 가지고 있는 노드를 중앙노드라고 부를 수 있다.

- **GNN  Task**
    - Node : 특정 노드가 어떤 레이블에 속하는지
    - Edge : 연결되지 않은 두 정점이 연결가능성이 있는지
    - Graph : 그래프 자체가 어떤 레이블에 속하는지
    ****
- **GNN의 구성 요소**

 **GNN에서 그래프를 구성하기 위해서는 3가지가 필요하다.**

1. **Vertex(node)**
2. **Edge**
3. **Feature**

<img width="944" alt="2" src="https://user-images.githubusercontent.com/79856225/230766656-19987636-5062-43af-ba06-cade7337f271.png">

**—# Vertext와 Edge와의 관계를 adjacency matrix(인접행렬)로 나타냄**

**—# Feature는 Feature metrix(특징 행렬)로 나타냄**

**Graph represctation learning이 먼저 시작하고 딥러닝을 접목시킨 것이 GNN이다.**

**추천 시스템에 사용되는 그래프 신경망(GNN)기법은 5가지가 존재한다.**

- **1. GCN(Graph Convolutional Network)**

- **2. GraphSAGE(Graph SAmple and aggreGatE)**
    
- **3. GAT(Graph Attention Network)**

- **4. GGNN(Graph Gated Neural Network)**
    
- **5. HGNN(Hypergraph Neural Network)**
    

### 3. **노드 임베딩**

**GNN은 여러 노드들의 고차원 정보를 저차원 공간으로 임베딩하여 그 특성을 파악한다.**

그래프 데이터 분석에서 노드 임베딩은 각 노드를 벡터 형태로 변환하는 것을 의미한다. 이를 통해 노드 간의 유사도를 계산하거나, 머신러닝 모델의 입력으로 활용할 수 있다.

예를 들어, 소셜 네트워크 그래프에서 각 노드는 사용자를 나타내고, 각 노드의 임베딩은 해당 **사용자의 특성을 나타내는 벡터로 변환**다. 이렇게 변환된 벡터를 이용해 **사용자 간의 유사도**를 계산하거나, 머신러닝 모델의 입력으로 활용할 수 있다. 또한, 임베딩은 다른 그래프 데이터 분석 알고리즘과 결합하여 그래프의 정보를 보다 효과적으로 활용할 수 있도록 한다.

### 3-1. 임베딩 종류

1. **그래프 스펙트럴 방법: 그래프 스펙트럴 방법은 노드 임베딩을 특잇값 분해(SVD)나 라플라스 행렬(Laplacian matrix) 등의 그래프 스펙트럴 분석을 통해 추출 이 방법은 그래프 전체의 정보를 이용해 노드 임베딩을 학습하며, 그래프의 대칭성과 성질을 이용해 임베딩을 생성한다. 대표적으로 DeepWalk, node2vec, LINE, SDNE 등이 있다.**

1. **그래프 신경망 방법: 그래프 신경망 방법은 메시지 패싱(Message Passing)을 이용해 노드의 임베딩을 학습한다. 메시지 패싱은 이웃 노드들과의 정보교환을 통해 노드의 임베딩을 계산한다. 이 방법은 노드간의 구조적인 관계와 특성을 잘 반영할 수 있으며, 그래프의 구조와 노드의 특성을 모두 고려할 수 있다. 대표적으로 GCN, GAT, GraphSAGE, Graph Convolutional Matrix Completion (GCMC) 등이 있습니다.**
- **Neighborhood-based Methods**
    
    노드의 임베딩을 학습하기 위해 **노드의 이웃 노드들의 특징을 이용하는 방법**. 이웃 노드들의 특징을 평균 내거나, 가중 평균을 취하는 등의 방법으로 노드의 임베딩을 계산한다. 예를 들어, **GCN(Graph Convolutional Network)은 이웃 노드들의 특징과 가중치를 합해서 노드의 임베딩**을 계산한다.
    
- **Random Walk-based Methods**
    
    노드의 임베딩을 학습하기 위해 **무작위로 그래프를 탐색하는 방법**입니다. 무작위로 그래프를 탐색하면서 노드의 이웃 노드들과의 유사도를 계산하고, 이를 이용해 노드의 임베딩을 학습합니다. 예를 들어, **DeepWalk는 무작위로 그래프를 탐색하**면서 각 노드와 인접한 노드들의 시퀀스를 생성하고, 이를 이용해 Word2Vec과 유사한 방법으로 노드의 임베딩을 학습합니다.
    
- **Spectral-based Methods**
    
    노드의 임베딩을 학습하기 위해 **그래프의 라플라시안 행렬을 이용**하는 방법입니다. 그래프의 라플라시안 행렬을 이용하면 그래프의 **고유벡터를 계산**할 수 있으며, 이를 이용해 노드의 임베딩을 계산합니다. 예를 들어, **GraphSAGE**는 그래프의 라플라시안 행렬을 이용해 노드의 임베딩을 계산합니다.
    
- **Attention-based Methods**
    
    노드의 임베딩을 학습하기 위해 **노드 간의 상호작용을 모델링**하는 방법입니다. 이 방법은 노드 간의 유사도를 계산하고, 이를 이용해 노드의 임베딩을 계산합니다. 예를 들어, **GAT(Graph Attention Network)은 이웃 노드들과의 상호작용을 계산하는데, 이를 위해 어텐션 메커니즘을 사용**합니다
    

**메시지 기반 노드 임베딩** 

<img width="954" alt="3" src="https://user-images.githubusercontent.com/79856225/230766659-15175c71-f97f-4204-a4be-8380ee043f96.png">

- A 노드에 특징을 업데이트 하기 위해서 자신과 연결된 이웃 노드들의 특징을 집계하여 자신의 특징을 업데이트 하는 방식으로 1번 연결된 이웃에 대한 특징만을 집계하는것으로 인공지능 One-layer와 유사하다.

<img width="776" alt="4" src="https://user-images.githubusercontent.com/79856225/230766663-c0c1aafb-a4cb-4b69-89b9-40d232d92e2a.png">

- 위와 같은 방식에서 A와 이웃된 노드의 또 다른 이웃들의 정보를 기준으로 레이어를 증가시킬 수 있다.

https://github.com/pyg-team/pytorch_geometric

### **데이터 셋**

1. Cora: 컴퓨터 과학 논문 데이터셋으로, 논문을 노드로, 각 논문의 키워드를 feature로 갖고 있다.
2. Citeseer: Cora와 비슷한 데이터셋으로, 컴퓨터 과학 분야의 논문을 노드로, 논문의 키워드를 feature로 갖고 있다.
3. Pubmed: 의학 분야의 논문 데이터셋으로, 논문을 노드로, 논문의 키워드를 feature로 갖고 있다.
4. Reddit: 소셜 미디어 사이트인 Reddit의 서브레딧 데이터셋으로, 각 포스트를 노드로, 사용자가 작성한 텍스트를 feature로 갖고 있다.
5. PPI (Protein-Protein Interaction): 단백질 상호작용 데이터셋으로, 각 단백질을 노드로, 단백질의 특징을 feature로 갖고 있다.

PyTorch Geometric에서는 TUDataset, Planetoid, Coauthor 등 다양한 데이터셋을 제공하고 있고,  DGL에서도 Reddit, Amazon 등 대표적인 GNN 데이터셋을 제공한다.

### 라이브러리

**Python에서 GNN 모델 설계를 지원하는 다양한 라이브러리들이 존재한다.**

1. PyTorch Geometric: PyTorch Geometric는 PyTorch 기반의 GNN 라이브러리로 대규모 그래프에서 GNN을 학습시키기 위한 다양한 유틸리티 함수와 함께 다양한 GNN 모델을 구현할 수 있다.
2. Deep Graph Library (DGL): DGL은 MXNet, PyTorch 및 TensorFlow에서 GNN 모델을 구현하고 학습시키기 위한 라이브러리. 여러 가지 그래프 레이아웃과 함께 다양한 GNN 모델과 레이어를 구현할 수 있다.
3. Spektral: Spektral은 Keras 기반의 GNN 라이브러리로 다양한 GNN 모델을 쉽게 구현하고 학습시킬 수 있다.
4. NetworkX: NetworkX는 Python에서 네트워크 분석을 위한 라이브러리입니다. NetworkX를 사용하여 GNN 모델을 구현하고 학습시킬 수 있다.




</div>
</details>



<details>
<summary> GCN(Graph Convolution Network)  </summary>
<div markdown="1">   


<img width="769" alt="1" src="https://user-images.githubusercontent.com/79856225/230766897-63c12a23-323b-4e4d-b180-22e513c1679f.png">

<img width="956" alt="2" src="https://user-images.githubusercontent.com/79856225/230766909-621ad552-d94b-4069-85de-42024d0635ce.png">

<img width="852" alt="3" src="https://user-images.githubusercontent.com/79856225/230766915-83914854-a906-4f31-a481-4bd6cec9bfec.png">

<img width="1099" alt="4" src="https://user-images.githubusercontent.com/79856225/230766920-ae657b22-cf52-44cb-9823-da3b4670042a.png">

H → 특징 행렬의 Coulmn을 통과

<img width="1088" alt="5" src="https://user-images.githubusercontent.com/79856225/230766925-2085f36d-dab7-46cb-b1e2-e17a2ea25351.png">

<img width="1256" alt="6" src="https://user-images.githubusercontent.com/79856225/230766926-c6156126-ed8b-4929-accb-89c8c476ccbc.png">

- A = 인접 행렬
- H = 특징 행렬
- W = 가중치 행렬

### **HW (특징 행렬 X 가중치 행렬)**

- 현재 예제에서는 가중치 행렬의 필터 갯수를 6개로 했지만 보통 16인듯

<img width="1232" alt="7" src="https://user-images.githubusercontent.com/79856225/230766928-bcc5641e-5d7d-4367-b42f-59830aea3932.png">

### A**HW (인접행렬 X 특징 행렬 X 가중치 행렬)**


<img width="1227" alt="8" src="https://user-images.githubusercontent.com/79856225/230766929-0e510137-2745-4eb7-80f6-515c2a46efaa.png">

**READOUT  - Permutation Invariance**

- 1번 그래프와 2번 그래프는 같은 그래프이지만 특징 행렬의 표현이 달라짐
- 그래프는 순서의 상관없이 같은 값이 나와야 함

<img width="1069" alt="9" src="https://user-images.githubusercontent.com/79856225/230766930-a4d5a443-cf0e-44d4-9756-85d37c101989.png">

**마지막 H(특징 행렬)에 MLP를 적용해서 벡터로 만들어서 활성화 함수를 통과** 

**Overall**

X → H(특징 행렬)

A → A(인접 행렬)

<img width="1170" alt="10" src="https://user-images.githubusercontent.com/79856225/230766931-7e869491-a76d-407e-8e3d-b98bd2ee973c.png">
### **Cora Dataset을 이용하여 GCN 논문 실습(Ensigner)**

[https://www.youtube.com/watch?v=JfBMCFVEuoM](https://www.youtube.com/watch?v=JfBMCFVEuoM)

### 1. Graph Convolution Networks(GCN)

- SEMI-SUPERVISED CLASSIFICATION WITH RAPH CONVOLUTIONAL NETWORKS
    
    [1609.02907.pdf](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0243e7f4-b4b7-4f93-8eee-764d06ff66ea/1609.02907.pdf)
    

ICLR 2017년에 나온 GCN에 대해 자세하게 다룬 첫 논문

### 2. Cora dataset

- Nodes = publications(책, 또는 논문)
    - 2708개의 publications(책, 논문)들이 있으며 7개의 라벨링이 되어 있음
- Edges = Citations(인용)
    - 각 논문당 인용에 대한 5429의 링크들이 존재
- Node Features = Word vectors
    - 하나의 노드에는 1433사이즈의 유니크한 words가 있다.

**구성**

Cora dataset은 2개의 파일로 구성되어 있다.

1. **Cora.content**

<img width="606" alt="11" src="https://user-images.githubusercontent.com/79856225/230766932-06e8f268-19a4-4b8b-aaa2-21fe8bfbbceb.png">

- Paper id : 논문의 고유 ID(논문의 이름이 아님)
- Word attributes :  (특징 벡터) 각 논문의 특징을 나타내는 키워드 값을 벡터화
- Class label : 각 논문이 어떤 주제인지 알 수 있음

1. **Cora.cites**
    
    <img width="632" alt="12" src="https://user-images.githubusercontent.com/79856225/230766934-144d17af-af75-4b64-a894-6ba834c042b1.png">
    
- ID of cited paper :  인용된 논문
- ID of citing paper :  인용하는 논문
    
    **—#**  **오른쪽 논문이 왼쪽 논문을 인용 1033 논문이 35논문을 인용**
    

### 3. 코드 실습

### **데이터 불러오기**

- **인접 행렬**
    - sparse 행렬(서로서로 연결된 비율이 매우 낮음)
    - 약 13,264개가 Not nonzero, 행렬의 사이즈는 2,709 X 2,709이다.
    - 약 0.18퍼센트만이 데이터에 값이 있음
- 특징 벡터
    - 각 노드에 해당하는 워드가 임베딩 되어 벡터 형태로 저장
- 레이블
    - 7개의 레이블을 클래스 번호로 레이블링(카테고리화)
- 학습 데이터
    - 0 ~ 139(140)개 데이터를 사용
- 검증 데이터
    - 200 ~ 499(300)개 데이터를 사용
- 테스트 데이터
    - 500 ~ 1400(1000)개를 사용

통상적으로 학습 : 7 검증 : 1 테스트 : 2 이지만 각자에 맞게 설정

### Model(Pytorch)

1. **Model 정의**
- **GraphConvolution**

```python
from torch import nn
from torch.nn.parameter import Parameter
import torch
import torch.nn.functional as F
import math

class GraphConvolution(nn.Module):
    def __init__(self, feature_numbers, out_numbers, bias=False) -> None:
        super().__init__()
        self.bias = bias
        self.w = Parameter(torch.FloatTensor(feature_numbers, out_numbers))
        if bias:
            self.b = Parameter(torch.FloatTensor(out_numbers))
        self.reset_parameters()
        
    def reset_parameters(self):
        stdv = 1. / math.sqrt(self.w.size(1))
        self.w.data.uniform_(-stdv, stdv)
        if self.bias is not False:
            self.b.data.uniform_(-stdv, stdv)
            
    def forward(self, x, adj):
		#-- input data 
		#-- X = 특징 행렬
		#-- adj = 인접 행렬(sparse matrix)
        support = torch.mm(x, self.w)
        out = torch.spmm(adj, support)
		#-- spmm(sparse mulple : sparse행렬 연산시 적은 메모리 사용 효율적으로 처리)
        if self.bias:
            out = out + self.b

        return out
```

- **NodeClassificationGCNN**

```python
class NodeClassificationGCNN(nn.Module):

    def __init__(self, feature_num, node_representation_dim, nclass, droupout=0.2, bias=False) -> None:
        super().__init__()
#-- 특징 행렬의 Column, Demention(CNN에서의 채널 수), output_dim
        self.gconv1 = GraphConvolution(feature_num, node_representation_dim, bias)
#-- 이전 레이어에서 나온 output, 최종 output class(7)
        self.gconv2 = GraphConvolution(node_representation_dim, nclass, bias)
        self.dropout = droupout

    def forward(self, x, adj):
        x = F.relu(self.gconv1(x, adj))
        x = F.dropout(x, self.dropout, self.training)
        x = F.relu(self.gconv2(x, adj))
        return F.log_softmax(x, dim=1)
#-- log를 이용하여 -무한대 값을 출력 가능
```

1. **Model 실행**

```python
from GCNN import NodeClassificationGCNN

#-- 특징벡터의 column개수, 256(CNN에서의 필터의 개수), 클래수 개수)
model = NodeClassificationGCNN(features.shape[1], 256, np.max(labels.detach().numpy())+1)
```

- **학습**

```python
import torch.optim as optim
import torch.nn.functional as F

epochs=100
optimizer = optim.Adam(model.parameters(),lr=0.01)
train_losses=[]
val_losses=[]
train_accuracy=[]
val_accuracy=[]
for epoch in range(epochs):
    model.train()
    train_labels=labels[idx_train]
    val_labels=labels[idx_val]
    
    
    optimizer.zero_grad()
    output = model(features, adj)
    train_loss=F.nll_loss(output[idx_train],train_labels)
    train_losses.append(train_loss)
    t_a=accuracy(output[idx_train],train_labels)
    train_accuracy.append(t_a)
    print(f"Training epoch {epoch} ; accuracy: {accuracy(output[idx_train],train_labels)}; loss: {train_loss.item()}")
    train_loss.backward()
    optimizer.step()
    
    model.eval()
    output = model(features, adj)
    val_loss=F.nll_loss(output[idx_val],val_labels)
    val_losses.append(val_loss)
    v_a=accuracy(output[idx_val],val_labels)
    val_accuracy.append(v_a)
    print(f"Validation epoch {epoch} ; accuracy: {accuracy(output[idx_val],val_labels)}; loss: {val_loss.item()}")
```

</div>
</details>





<details>
<summary> LightGCN   </summary>
<div markdown="1">   


**LightGCN**은 **Collaborative Filtering** (CF)에서의 **User-Item Interaction Matrix(**사용자-아이템 상호작용 매트릭스)를 활용한 **추천 시스템에서 사용되는 모델 중 하나이다.**

LightGCN은 그래프 신경망 모델 중 **가장 간단하면서도 성능이 우수한 모델 중 하나이다.** 모델 구조는 사용자와 아이템 간의 상호작용을 표현하는 **유저-아이템 행렬을 이용하여 그래프를 만든다**. 이때 그래프의 **각 노드는 유저와 아이템**을 나타내며, **각 엣지는 유저와 아이템 간의 상호작용**을 나타냅니다.

LightGCN은 다른 CF(협업 필터링) 모델과 달리, User와 Item간의 **interaction(상호작용)** 매트릭스를 이용하여 User와 Item을 **Embedding**시키는 작업만을 수행한다. 즉, User-Item 간의 **side-information이나 Auxiliary feature를 사용하지 않는다.**

LightGCN에서 사용되는 GCN은 **message passing**과정에서 User와 Item 간의 **interaction이 Embedding 공간에서 얼마나 가까운지**를 계산하는데에만 사용된다 이를 위해 User와 Item 간의 interaction matrix를 정규화하고, GCN의 weight를 1로 고정하는 등의 가벼운 방식을 적용하여 모델의 학습 속도를 높인다.

**LightGCN의 장점**

- 사용할 Auxiliary feature가 없어 매우 가볍고 단순하며 빠른 속도를 보여줌.
- SOTA(CF모델)보다 높은 성능을 보여줌

**LightGCN의 단점**

- cold-start problem을 해결하지 못함
- 과적합될 가능성 존재
- 데이터가 매우 sparse한 경우 학습 성능이 떨어짐

### 코드 구현

- LightGCN 논문 요약
    
    넷플릭스, 트위터, 스포티파이 같은 디지털 서비스 뒤에는 사용자의 관심사를 예측하고 구매, 시청, 읽기에 영향을 주는 추천 시스템이 있다. 이 글에서는 PyTorch와 PyG로 구현된 그래프 기반 협업 필터링 추천 시스템 모델인 LightGCN에 대해 살펴본다.
    
    [LightGCN with PyTorch Geometric](https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e)
    

**목표 : 사용자가 아직 평점을 매기지 않은 영화를 추천**

- 노드 : 사용자, 영화
- 엣지 : 사용자와 영화 간의 상호작용(평점

**데이터 전처리** 

- 사용자가 좋아할 만한 영화만 추천하고 싶기 때문에, 0.5 ~ 5점 척도였던 평점(엣지)를 4점 이상으로만 포함하는 방식으로 데이터를 전처리

**훈련 목표(Task)**

- 두 노드 사이에 유효한 **엣지가 존재**하는지 여부를 예측하는 엣지 예측 작업
- 이를 위해 그래프 구조에서 사용자와 영화 노드 간의 구분이 없는 동질 그래프로 설정
- 그래프가 사용자와 영화 사이에만 에지가 존재하는 이분형 그래프
- 사용자와 영화를 동일한 유형의 노드로 취급할 수 있음.
- 동종 그래프 표현의 인접 행렬은 희소 행렬
    - 희소 행렬 : 인접 행렬의 요소 대부분이 0

</div>
</details>



<!-- <details>
<summary> 4주차  </summary>
<div markdown="1">   

</div>
</details> -->


</div>
</details>


<details>
<summary> 5주차  (GNN을 이용한 추천 시스템 구현) </summary>
<div markdown="1">   



</div>
</details>

<!-- 
<details>
<summary>  </summary>
<div markdown="1">   

</div>
</details> -->
