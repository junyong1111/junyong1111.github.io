---
title: "YOLO_NAS_튜토리얼"
header:
#   overlay_image: /assets/images/
# teaser: /assets/images/flutter.png
show_date: false
layout: single
date: 2023-06-28
classes:
  - landing
  - dark-theme
categories:
  - AI, YOLO, Objectdectection
---

# YOLO-NAS vs YOLOv8

참고 블로그 : 

[YOLO-NAS vs. YOLOv8: A Comprehensive Comparison](https://www.augmentedstartups.com/blog/yolo-nas-vs-yolov8-a-comprehensive-comparison)

객체 인식 분야에서 가장 인기 있고 효율적인 모델 중에는 YOLO 시리즈가 있다. 해당 블로그에서는 2가지의 최신 모델을 비교하고 각가의 모델의 특징을 조사한다.

**YOLO 간략한 역사**

인기 있는 객체 감지 및 이미지 분할 모델인 YOLO(You Only Look Once)는 워싱턴 대학의 조셉 레드몬과 알리 파르하디가 개발했다. 2015년에 출시된 YOLO는 빠른 속도와 정확성으로 빠르게 인기를 얻었습니다.

- 2016년에 출시된 YOLOv2는 배치 정규화, 앵커 박스, 차원 클러스터를 통합하여 기존 모델을 개선했다.
- 2018년에 출시된 YOLOv3는 보다 효율적인 백본 네트워크, 다중 앵커, 공간 피라미드 풀링을 사용하여 모델의 성능을 더욱 향상시켰다.
- 2020년에는 모자이크 데이터 증강, 새로운 앵커 프리 감지 헤드, 새로운 손실 기능 등의 혁신을 도입한 YOLOv4가 출시되었다.
- YOLOv5는 모델의 성능을 더욱 개선하고 하이퍼파라미터 최적화, 통합 실험 추적, 널리 사용되는 내보내기 형식으로의 자동 내보내기 등의 새로운 기능을 추가했다.
- YOLOv6는 2022년에 메이퇀이 오픈소스로 공개했으며, 메이퇀의 여러 자율주행 배송 로봇에 사용되고 있습니다.
- YOLOv7은 COCO 키포인트 데이터 세트에 포즈 추정과 같은 추가 작업을 추가했다.
- YOLOv8은 Ultralytics의 최신 버전이다. 최첨단 최신(SOTA) 모델인 YOLOv8은 이전 버전의 성공을 기반으로 성능, 유연성 및 효율성을 향상시키기 위해 새로운 기능과 개선 사항을 도입했다. YOLOv8은 감지, 세분화, 포즈 추정, 추적, 분류를 포함한 모든 범위의 비전 AI 작업을 지원한다. 이러한 다재다능함 덕분에 사용자는 다양한 애플리케이션과 도메인에서 YOLOv8의 기능을 활용할 수 있다.
    
    [Home](https://docs.ultralytics.com/)
    

## 1. 모델 개요

### **1.1 YOLO-NAS**

 YOLO-NAS는 YOLOv6와 YOLOv8에서 영감을 받은 객체 탐지를 위한 최첨단 기초 모델이다. YOLO-NAS는 작은 물체 감지, 현지화 정확도 및 계산당 선능 비율을 크게 향상시켰다. **실시간 장치 애플리케이션에 이상적**이며 다양한 데이터 세트에서 기존 YOLO 모델을 능가한다.

### 1.2 YOLOv8

 YOLOv8은 이전 모델의 성공을 기반으로 한 YOLO 시리즈의 최신 버전입니다. **새로운 트랜스포머** 기반 아키텍처를 도입하여 정확도와 성능이 향상되었다. YOLOv8은 지식 증류 및 의사 라벨링이 포함된 고급 훈련 체계를 자랑하며, 강력한 객체 감지 모델이다.

## 2. 모델 아키텍쳐

### 2**.1 YOLO-NAS**

 YOLO-NAS는 전작에 비해 양자화 성능을 향상시키기 위해 설계된 새로운 양자화 친화적인 기본 특징으로 한다. 이 새로운 블록은 YOLO-NAS가 효율성을 유지하면서 더 높은 정확도를 달성할 수 있게 해준다.

### 2**.2** YOLOv8

YOLOv8은 이전 YOLO 모델과 차별화되는 트랜스포머 기반 아키텍쳐를 사용하며 이전 모델보다 정확도와 성능을 개선했다.

## 3. 학습

### 3**.1 YOLO-NAS**

 YOLO-NAS COCO, Object365 데이터 세트 및 Roboflow 100에 대한 사전교육을 받은 모델을 사용하며 사전 훈련된 모델을 사용하여 지식 증류의 이점을 얻는다.

### 3**.2** YOLOv8

YOLOv8 또한 지식 증류와 라벨링을 사용한다. 하지만 YOLO-NAS가 사용하는 Object365등에 대한 사전 교육이 부족하여 특정 객체 탐지 작업에서 성능에 잠재적으로 영향을 미친다.

## 4. 훈련 후 정량화

훈련 후 정량화는 훈련된 후 컴퓨터 비전 모델을 단순화하여 더 효울적으로 만드는 기술이다. 

### 4**.1 YOLO-NAS**

 YOLO-NAS는 훈련 후 네트워크를 INT8로 변환하는 훈련 후 양자화(PTQ)를 지원한다.

### 4**.2** YOLOv8

YOLOv8은 현재 PTQ를 지원하지 않으며, 이느 계산 자원이 낮은 애플리케이션에서 효율성을 제한할 수 있다.

## 5. 성능 지표

![스크린샷 2023-06-27 오후 7.02.29.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b58eae99-dfc0-43bb-bb06-622828e631ba/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-06-27_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_7.02.29.png)

## 6. 작은 객체 탐지 및 위치 정확도

### 6.1 YOLO-NAS

**YOLO-NAS는 작은 물체를 감지하는 데 탁월하며 향상된 측위 정확도를 제공**한다. 이러한 개선 사항은 다양한 사용 사례, 특히 작거나 감지하기 어려운 물체와 관련된 사용 사례에서 전반적인 우수성에 기여한다.

### 6.2 YOLOv8

YOLOv8은 인상적인 물체 감지 모델이지만, 작은 물체 감지 및 위치추적 정확도에서는 YOLO-NAS에 비해 부족하다

## 7. 실시간 엣지 디바이스 어플리케이션

### 7.1 YOLO-NAS

YOLO-NAS는 효율성, 정확성, 컴퓨팅당 성능 비율로 인해 실시간 엣지 디바이스 애플리케이션에 이상적이다. 이 모델의 PTQ 및 양자화 친화적인 기본 블록은 이러한 애플리케이션에 대한 적합성을 더욱 향상시킨다.

### 7.2 YOLOv8

YOLOv8은 경쟁 제품에 비해 PTQ가 부족하고 효율성이 낮기 때문에 실시간 엣지 장치 애플리케이션에는 YOLO-NAS만큼 적합하지 않는다. 하지만 OpenCV AI 키트와 같은 임베디드 장치에서 실행할 수 있다.

## 8. 요약

| 영역 | YOLO-NAS | YOLOv8 |
| --- | --- | --- |
| 작은 물체 감지 | 뛰어남 | 제한적 |
| 로컬라이제이션 정확도 | 뛰어남 | 제한적 |
| 학습 후 정량화 | 용이함 | 어려움 |
| 실시간 에지 디바이스 애플리케이션 | 가능함 | 가능함 |
| 정확도 | 높음 | 높음 |
| 처리 속도 | 빠름 | 빠름 |
| 효율성 | 높음 | 높음 |


## YOLO-NAS

---

먼저 신경 구조 검색에 대해 살펴보겠습니다. **NAS(Nural Archtecture Search)**

신경 구조 검색은 세 가지 구성 요소로 이루어져 있다.

1. 첫 번째는 검색 공간 또는 검색 공간으로, 선택할 수 있는 유효한 아키텍처의 집합을 정의한다.
2. 두 번째 구성 요소는 검색 알고리즘으로, 검색 공간에서 가능한 아키텍처를 전송하는 방법을 담당하는 검색 알고리즘이다.
3. 세 번째 구성 요소는 평가 전략으로, 후보 아키텍처를 비교하는 데 사용되는 가치 평가 전략이다.

AutoNeck는 "자동 신경망 구성"을 의미하며, 객체 검출 모델을 탐색하기 위해 사용된다. 이를 위해 초기 검색 공간을 생성하고, NVIDIA T4에 최적화된 YOLO NAS의 최적 아키텍처를 찾기 위해 GPU를 3800시간 동안 사용했다. 또한, 저지연성이 필요한 실시간 객체 검출은 자율 주행차 등 다양한 응용 프로그램에서 중요하다. 그러나 에지 디바이스의 자원은 제한적이므로 클라우드가 아닌 디바이스에 모델을 배포하는 것은 어려움이 있다. 이런 제약사항을 극복하기 위해 "양자화" 기술이 사용된다. 양자화는 모델 가중치의 정밀도를 낮춰 메모리 사용량을 줄이고 실행 속도를 높이는 과정을 의미한다. YOLO NAS에서 사용된 양자화 기법은 int8 양자화로, 모델 가중치를 Float32에서 1바이트로 변환하여 메모리를 절약한다. 이를 위해 "EurVgg"라는 새로운 구성 요소를 사용하였으며, 이는 양자화 후 정확도 손실을 크게 개선하는 역할을 한다. 또한, quantization으로 인한 정확도 손실을 개선하기 위해 "Sharif Vgg" 블록이 사용되었으며, Uranus Hybrid Quantization 기술을 통해 모델의 특정 레이어에만 양자화를 적용하여 정보 손실과 지연 시간을 균형있게 조절하였다. 이러한 기술들을 통해 객체 검출 모델을 자동으로 탐색하고 최적화하여, 자동차, 휴대폰 등의 장치에 대규모 모델을 배포하면서도 저지연성을 유지할 수 있다.

![스크린샷 2023-06-28 오후 3.09.56.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/07c68990-9bf6-4729-bc72-7a1c3d3488fc/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-06-28_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_3.09.56.png)

YOLO NAS는 기존 YOLO 모델의 한계인 양자화 지원 부족과 정확도 부족과 같은 중요한 요소들을 개선하기 위한 최신 딥 러닝 기술을 적용한 모델이다.

YOLO NAS의 핵심 구성 요소는 "백본(Backbone)", "넥(Neck)", "헤드(Head)"로 구성되어 있다. 백본은 입력 이미지에서 특징을 추출하는 부분으로, YOLO NAS는 밀집(dense) 블록과 희소(sparse) 블록을 결합한 이중 경로 백본을 사용한다. 넥은 백본에서 추출된 특징을 향상시키고 다양한 스케일에서 예측을 생성하는 부분이다. 다중 스케일 피라미드를 사용하여 백본의 다양한 레벨에서 특징을 결합하고 예측을 생성한다. 헤드는 모델의 최종 분류 및 회귀 작업을 수행하는 부분으로, 분류 분기와 회귀 분기로 구성되어 있다.

YOLO NAS 모델은 YOLO, YOLO NAS Small, YOLO NAS Medium, YOLO NAS Large와 같이 세 가지 다른 모델이 제공된다. 이 모델들은 유명한 Object365 벤치마크 데이터셋을 기반으로 사전 훈련되었으며, 추가적인 훈련 및 데이터 라벨링을 통해 성능을 향상시켰다. YOLO NAS 모델은 Roboflow A100 데이터셋에서 복잡한 객체 검출 작업을 처리하는 능력을 보였으며, 다른 YOLO 모델들보다 우수한 성능을 발휘한다고 소개되었다.

YOLO NAS는 Neural Architecture Search (NAS) 기술을 사용하여 개발된 모델로, 효율적이고 고성능의 딥 러닝 모델을 생성할 수 있다. Neural Architecture Search는 특정 작업에 대한 최적의 신경망 아키텍처를 자동으로 탐색하는 과정이다. 이를 위해 다양한 아키텍처의 탐색 공간을 탐색하고 가장 효율적이고 고성능인 아키텍처를 선택한다. YOLO NAS인 Uranus의 주요 특징을 살펴보면, 작은 객체의 검출 능력을 향상시키고 정확도를 향상시키며 계산 비율에 대한 성능을 높인다. 비교 결과로 YOLO v5, YOLO v7, YOLO v8 모델보다 Uranus가 우수한 성능을 보인다.

 YOLO NAS의 다른 주요 특징은 다음과 같다. 첫째로, YOLO NAS 아키텍처에는 양자화를 지원하는 블록과 최적화된 성능을 위한 선택적 양자화가 포함되어 있다. 둘째로, NAS 사전 훈련 모델은 Coco 데이터셋, Object365 데이터셋, Roboflow Hundred 데이터셋으로 사전 훈련되어 있으며, Roboflow Hundred 데이터셋에서 기존 YOLO 모델들보다 우수한 성능을 보인다. 마지막으로, 훈련 후 양자화 과정을 거쳐 YOLO NAS 모델을 Int8 양자화된 버전으로 변환하여 다른 YOLO 모델보다 더 효율적이다.

## YOLO_NAS Tutorial

---

## 1. 필요 라이브러리 다운로드

로컬에서 사용시 python 3.10 버전을 사용해야 한다 3.11 버전은 아직 에러가 많음

```bash
#-- requirements.txt
super-gradients==3.1.2
opencv-python
```

```bash
pip install -r requirements.txt
```

## 2. 코드 작성

**이미지에서 YOLO 사용**

```python
import cv2
import torch
from super_gradients.training import models

#-- GPU 설정
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
use_cuda = torch.cuda.is_available()
print(use_cuda)
if use_cuda:
  print(torch.cuda.get_device_name(0))

#-- 이미지 불러오기
img = cv2.imread("이미지경로")
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

#-- 사전학습된 Yolo_nas_small 모델 불러오기(빠르지만 정확도가 낮음)
model_s = models.get("yolo_nas_s", pretrained_weights ="coco").to(device)
model_m = models.get("yolo_nas_m", pretrained_weights ="coco").to(device)
model_l = models.get("yolo_nas_l", pretrained_weights ="coco").to(device)

out_s = model_s.predict(img, conf = 0.3)
out_m = model_m.predict(img, conf = 0.3)
out_l = model_l.predict(img, conf = 0.3)

out_s.show()
out_m.show()
out_l.show()
```

**웹캠에서 YOLO 사용**

```python
import cv2
import torch
from super_gradients.training import models

#-- GPU 설정
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
use_cuda = torch.cuda.is_available()
print(use_cuda)
if use_cuda:
  print(torch.cuda.get_device_name(0))

#-- 사전학습된 Yolo_nas_small 모델 불러오기(빠르지만 정확도가 낮음)
model = models.get("yolo_nas_s", pretrained_weights ="coco").to(device)
model.predict_webcam(conf =0.7)
```